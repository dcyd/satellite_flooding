{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFD中每个灾害事件的duration和不平等性\n",
    "Chongyang Du, Jan 9, 2024\n",
    "\n",
    "\n",
    "首先识别每个灾害事件覆盖的子行政单元\n",
    "生成每个行政单元在此次灾害事件下的duration(暴露人群人均duration)\n",
    "\n",
    "分析人均duration和人均收入或消费之间的相关性，期待的结论：duration越长的地区，越贫困的地区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=3TRfDVP2-1RDcm4KRxMQawcRu6z9h6V3ETM6WP2OYQc&tc=Y7afYEMWk-ootbl9Jbs280hAS_mOmwQk0EV-a0f6q9g&cc=ooP6BEzNP7FincWkdL9d-V8HNX08wVhcR8Tc8iU0zJk>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=3TRfDVP2-1RDcm4KRxMQawcRu6z9h6V3ETM6WP2OYQc&tc=Y7afYEMWk-ootbl9Jbs280hAS_mOmwQk0EV-a0f6q9g&cc=ooP6BEzNP7FincWkdL9d-V8HNX08wVhcR8Tc8iU0zJk</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GFD上所有洪涝事件的ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chongyang Du\n",
    "# Jan 2, 2024\n",
    "\n",
    "# use this template to run the flood stats functions (area, population, etc.)\n",
    "# on an image collection and export results as a .tif\n",
    "\n",
    "import ee\n",
    "import geemap\n",
    "ee.Initialize()\n",
    "\n",
    "# from flood_stats import pop_utils\n",
    "import time, csv\n",
    "\n",
    "def get_flood_pop_pixel(flood_img):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        floodImage : the standard Earth Engine Image object outputted by the map_DFO_event function\n",
    "        roiGEO : the region of interest as an Earth Engine Geometry object\n",
    "\n",
    "    Returns:\n",
    "    -an image of people in the mapped flood from WorldPop data\n",
    "\n",
    "    \"\"\"\n",
    "    import ee\n",
    "    import geemap\n",
    "    ee.Initialize()\n",
    "    # ee.Authenticate()\n",
    "    roi_geo = flood_img.geometry()\n",
    "\n",
    "    # Import the LandScan image collection & permannt water mask\n",
    "    perm_water = ee.Image(\"JRC/GSW1_0/GlobalSurfaceWater\").select(\"transition\").eq(1).unmask()\n",
    "    # print('Band names:', flood_img.bandNames().getInfo())\n",
    "    def maskImages(img):\n",
    "        non_flood = img.select(\"flooded\")\n",
    "        water_mask = non_flood.multiply(perm_water.neq(1))\n",
    "        return img.select(\"flooded\").mask(water_mask)\n",
    "\n",
    "    def durationImages(img):\n",
    "            non_flood = img.select(\"flooded\")\n",
    "            water_mask = non_flood.multiply(perm_water.neq(1))\n",
    "            return img.select(\"duration\").mask(water_mask)\n",
    "\n",
    "    # Extract the final flood extent image data as its own variable for analysis\n",
    "    # flood_extent = maskImages(ee.Image(flood_img.select(\"flooded\")))\n",
    "    # flood_duration = durationImages(ee.Image(flood_img.select(\"flood_duration\")))\n",
    "    flood_extent = maskImages(ee.Image(flood_img))\n",
    "    flood_duration = durationImages(ee.Image(flood_img))\n",
    "\n",
    "\n",
    "    # # get pop from projects/global-flood-db/landscan\n",
    "    # # Get event year, match with the population year and clip to study are\n",
    "    # pop_all = ee.ImageCollection(\"projects/global-flood-db/landscan\")\n",
    "    # event_year = ee.Date(flood_img.get('began')).get('year')\n",
    "    # pop_img = ee.Image(pop_all.filterMetadata('year', 'equals', event_year)\\\n",
    "    #                 .first()).clip(roi_geo)\n",
    "    # pop_img = pop_img.updateMask(pop_img.gte(0)) # mask out bad data with negative values\n",
    "\n",
    "    # get pop from JRC/GHSL/P2016/POP_GPW_GLOBE_V1\n",
    "    pop_all = ee.ImageCollection(\"JRC/GHSL/P2016/POP_GPW_GLOBE_V1\")\n",
    "    # Get event year to match with the population year\n",
    "    # pop_img = ee.Image(pop_all.filterMetadata('system:index', 'equals', '2000')\\\n",
    "    #                 .first()).clip(roi_geo)\n",
    "    pop_img = ee.Image(pop_all.filterMetadata('system:index', 'equals', '2015')\\\n",
    "                    .first()).clip(roi_geo)\n",
    "\n",
    "\n",
    "    # Mask the world population dataset using the flood extent layer\n",
    "    pop_masked = pop_img.updateMask(flood_extent)\n",
    "\n",
    "    pop_duration = pop_masked.multiply(flood_duration)\n",
    "    return flood_extent, flood_duration, pop_img, pop_masked, pop_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# identify the administrative region covered by each flood event\n",
    "ee.Initialize()\n",
    "\n",
    "import time, csv\n",
    "# from flood_stats import pop_utils\n",
    "\n",
    "# Image Collection of flood maps, each needs layer called \"flooded\" that\n",
    "# is 1 = flooded, 0 = not flooded\n",
    "gfd = ee.ImageCollection('projects/global-flood-db/gfd_v3').filterMetadata('id','greater_than',1500)\n",
    "\n",
    "# Create Error Log file\n",
    "log_file = \"../error_logs/event_stats/pop_error_log_{0}.csv\".format(time.strftime(\"%d_%m_%Y\"))\n",
    "with open(log_file,\"w\", newline='') as out_file:\n",
    "    wr = csv.writer(out_file)\n",
    "    wr.writerow([\"error_type\", \"dfo_id\", \"error_message\"])\n",
    "\n",
    "# Create list of events from input fusion table\n",
    "event_ids = ee.List(gfd.aggregate_array('id')).sort()\n",
    "id_list = event_ids.getInfo()\n",
    "id_list = [int(i) for i in id_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dfo_centroid_y': -31.268059, 'dfo_main_cause': 'Monsoonal rain', 'gfd_country_name': \"['AUSTRALIA']\", 'dfo_centroid_x': 143.6978, 'glide_index': 'NA', 'slope_threshold': 5, 'dfo_severity': 2, 'system:footprint': {'type': 'LinearRing', 'coordinates': [[139.6005812730815, -17.518267010104264], [138.4040674236775, -17.51707155596811], [137.20519449393421, -17.518262275331107], [137.20471106885168, -37.68095660034486], [139.99941925183816, -37.680961429261664], [141.9936089883675, -37.680961430234674], [143.98779872401195, -37.680961424329006], [145.58315055189232, -37.68096143983046], [147.97617824298896, -37.680961381848334], [149.97321059715983, -37.68095662726775], [149.97272709473495, -17.518262280872825], [148.77385413322452, -17.51707158835981], [147.57734028086537, -17.518267026312603], [146.38082649061207, -17.517071608501123], [145.18431256933783, -17.518267014811364], [143.98779872401195, -17.51707157652277], [142.39244698359286, -17.51707158759303], [140.79709518683185, -17.517071570794638], [139.6005812730815, -17.518267010104264]]}, 'threshold_b1b2': 0.711, 'otsu_sample_res': 231.66, 'dfo_displaced': 200, 'id': 1586, 'cc': 'AUS', 'began': '2000-02-18', 'dfo_validation_type': 'News', 'composite_type': '3Day', 'dfo_country': 'Australia', 'countries': 'Australia', 'dfo_other_country': 'NA', 'dfo_dead': 1, 'gfd_country_code': \"['AS']\", 'ended': '2000-03-01', 'threshold_type': 'otsu', 'threshold_b7': 1815.18, 'system:asset_size': 8987006, 'system:index': 'DFO_1586_From_20000218_to_20000301'}\n",
      "dict_keys(['dfo_centroid_y', 'dfo_main_cause', 'gfd_country_name', 'dfo_centroid_x', 'glide_index', 'slope_threshold', 'dfo_severity', 'system:footprint', 'threshold_b1b2', 'otsu_sample_res', 'dfo_displaced', 'id', 'cc', 'began', 'dfo_validation_type', 'composite_type', 'dfo_country', 'countries', 'dfo_other_country', 'dfo_dead', 'gfd_country_code', 'ended', 'threshold_type', 'threshold_b7', 'system:asset_size', 'system:index'])\n",
      "AUS\n"
     ]
    }
   ],
   "source": [
    "first_image = gfd.first()\n",
    "\n",
    "# Retrieve information about the first image as a dictionary.\n",
    "first_image_info = first_image.getInfo()\n",
    "\n",
    "# Now you can print or inspect 'first_image_info' to see all properties.\n",
    "print(first_image_info['properties'])\n",
    "\n",
    "# If you want to see all property names (keys) of the first image:\n",
    "property_names = first_image_info['properties'].keys()\n",
    "print(property_names)\n",
    "\n",
    "print(first_image_info['properties']['cc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对每个洪涝灾害，识别覆盖的行政单元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFO 1586 is in AUS\n",
      "found 5 regions covered by the flood event\n",
      "calculated results, exporting results for DFO 1586...\n",
      "DFO 1587 is in MDG\n",
      "found 22 regions covered by the flood event\n",
      "calculated results, exporting results for DFO 1587...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\ee\\data.py:355\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 355\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\googleapiclient\\http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1/projects/earthengine-legacy/table:export?alt=json returned \"Request payload size exceeds the limit: 10485760 bytes.\". Details: \"Request payload size exceeds the limit: 10485760 bytes.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 149\u001b[0m\n\u001b[0;32m    143\u001b[0m     task \u001b[38;5;241m=\u001b[39m ee\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mExport\u001b[38;5;241m.\u001b[39mtable\u001b[38;5;241m.\u001b[39mtoDrive(\n\u001b[0;32m    144\u001b[0m         collection \u001b[38;5;241m=\u001b[39m regions_stats,\n\u001b[0;32m    145\u001b[0m         description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration_state_regions_\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(event_id))),\n\u001b[0;32m    146\u001b[0m         fileNamePrefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Data/GFD/region_duration/duration_state_regions_\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(event_id))),\n\u001b[0;32m    147\u001b[0m         fileFormat \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCSV\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 149\u001b[0m     \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\ee\\batch.py:129\u001b[0m, in \u001b[0;36mTask.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_type \u001b[38;5;241m==\u001b[39m Task\u001b[38;5;241m.\u001b[39mType\u001b[38;5;241m.\u001b[39mEXPORT_TABLE:\n\u001b[1;32m--> 129\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexportTable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_type \u001b[38;5;241m==\u001b[39m Task\u001b[38;5;241m.\u001b[39mType\u001b[38;5;241m.\u001b[39mEXPORT_VIDEO:\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\ee\\data.py:1697\u001b[0m, in \u001b[0;36mexportTable\u001b[1;34m(request_id, params)\u001b[0m\n\u001b[0;32m   1696\u001b[0m params \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m-> 1697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_prepare_and_run_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_cloud_projects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\n\u001b[0;32m   1699\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\ee\\data.py:1787\u001b[0m, in \u001b[0;36m_prepare_and_run_export\u001b[1;34m(request_id, params, export_endpoint)\u001b[0m\n\u001b[0;32m   1786\u001b[0m num_retries \u001b[38;5;241m=\u001b[39m MAX_RETRIES \u001b[38;5;28;01mif\u001b[39;00m request_id \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1787\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_projects_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\ee\\data.py:357\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 357\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "\u001b[1;31mEEException\u001b[0m: Request payload size exceeds the limit: 10485760 bytes.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 155\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(log_file,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mab\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m out_file:\n\u001b[0;32m    154\u001b[0m     wr \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(out_file)\n\u001b[1;32m--> 155\u001b[0m     \u001b[43mwr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExport Error\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExport Error DFO \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m - Cataloguing and moving onto next event\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(event_id))\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "# Load the shapefile\n",
    "shapefile_path = \"E:/code/Py_workplace/satellite_flooding/Data/gsap-maps-poverty/GSAP2.shp\"\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# # Convert GeoSeries to list of shapely geometries\n",
    "# gdf['geometry'] = gdf['geometry'].apply(lambda x: shape(x))\n",
    "\n",
    "for event_id in id_list:\n",
    "    # Get event date range, they can be passed as Strings\n",
    "    flood_event = ee.Image(gfd.filterMetadata('id', 'equals', event_id).first())\n",
    "    flood_event_info = flood_event.getInfo()\n",
    "    event_coun_code = flood_event_info['properties']['cc']\n",
    "    print(\"DFO {0} is in {1}\".format(event_id, event_coun_code))\n",
    "    \n",
    "    country_codes_list = event_coun_code.split(', ')\n",
    "\n",
    "    # try:\n",
    "    # Calculate flood stats\n",
    "    # flood_stats = pop_utils.getFloodPopbyCountry_GHSLTimeSeries(flood_event)\n",
    "    flood_extent, flood_duration, pop_img, pop_masked, pop_duration = get_flood_pop_pixel(flood_event)\n",
    "    # index = flood_stats.get(\"id\").getInfo()\n",
    "\n",
    "    # band_names = pop_masked.bandNames()\n",
    "    # # Retrieve the band names as a Python list (makes a call to the Earth Engine API).\n",
    "    # band_names_list = band_names.getInfo()\n",
    "    # print(\"Band names:\", band_names_list)\n",
    "\n",
    "    # Filter the regions covered by the flood event\n",
    "    gdf_coun = gdf[gdf['code'].isin(country_codes_list)]\n",
    "\n",
    "    # Step 1: Convert the Earth Engine Geometry to GeoJSON\n",
    "    flood_extent_geojson = flood_extent.geometry().getInfo()\n",
    "\n",
    "    # Step 2: Create a GeoSeries from the Earth Engine Geometry (now in GeoJSON format)\n",
    "    flood_extent_shapely = shape(flood_extent_geojson)\n",
    "    flood_extent_geoseries = gpd.GeoSeries([flood_extent_shapely])\n",
    "\n",
    "    # Step 3: Check for intersection between GeoDataFrame and the new GeoSeries\n",
    "    covered_regions = gdf_coun[gdf_coun.intersects(flood_extent_geoseries.iloc[0])]\n",
    "\n",
    "    print(\"found {0} regions covered by the flood event\".format(len(covered_regions)))\n",
    "\n",
    "    # Function to convert a row of the GeoDataFrame to an ee.Feature\n",
    "    def row_to_ee_feature(row):\n",
    "        geometry = ee.Geometry(row['geometry'].__geo_interface__)\n",
    "        # Remove the geometry from the row and use the rest as properties\n",
    "        properties = row.drop('geometry').to_dict()\n",
    "        return ee.Feature(geometry, properties)\n",
    "\n",
    "    # Apply the function to each row and create a list of ee.Feature\n",
    "    covered_regions_features = covered_regions.apply(row_to_ee_feature, axis=1)\n",
    "\n",
    "    # Combine features into an ee.FeatureCollection\n",
    "    covered_regions_fea_coll = ee.FeatureCollection(list(covered_regions_features))\n",
    "\n",
    "\n",
    "    # Get area of flood in the scale of the flood map\n",
    "    flood_area_img = flood_extent.multiply(ee.Image.pixelArea())\n",
    "    map_scale = flood_extent.projection().nominalScale()\n",
    "    \n",
    "    flood_extent, flood_duration, pop_img, pop_masked, pop_duration\n",
    "    pop_scale = pop_img.projection().nominalScale()\n",
    "\n",
    "    pop_masked_scale = pop_masked.projection().nominalScale()\n",
    "\n",
    "    pop_duration_scale = pop_duration.projection().nominalScale()\n",
    "\n",
    "    def get_regions_dura(ft):\n",
    "\n",
    "        pop_sum = pop_img.reduceRegion(\n",
    "        reducer = ee.Reducer.sum(),\n",
    "        geometry = ft.geometry(),\n",
    "        scale = pop_scale,\n",
    "        maxPixels = 1e9)\n",
    "\n",
    "        area_sum= flood_area_img.reduceRegion(\n",
    "        reducer= ee.Reducer.sum(),\n",
    "        geometry= ft.geometry(),\n",
    "        scale= map_scale,\n",
    "        maxPixels= 1e9)\n",
    "\n",
    "        pop_exposed= pop_masked.reduceRegion(\n",
    "        reducer= ee.Reducer.sum(),\n",
    "        geometry= ft.geometry(),\n",
    "        scale= pop_masked_scale,\n",
    "        maxPixels= 1e9)\n",
    "\n",
    "        pop_duration_mask = pop_duration.reduceRegion(\n",
    "        reducer= ee.Reducer.sum(),\n",
    "        geometry= ft.geometry(),\n",
    "        scale= pop_duration_scale,\n",
    "        maxPixels= 1e9)\n",
    "\n",
    "        pop_init_sum = pop_sum.get(\"population_count\")\n",
    "        pop_exposed_sum = pop_exposed.get(\"population_count\")\n",
    "        pop_duration_mask_sum = pop_duration_mask.get(\"population_count\")\n",
    "        area = area_sum.get(\"flooded\")\n",
    "        sys_id = ee.String(flood_event.get('system:index')).getInfo()\n",
    "\n",
    "        # Calculate the ratio of pop_duration_mask_sum to pop_exposed_sum\n",
    "        # Ensure that pop_exposed_sum is not zero to avoid division by zero error\n",
    "        pop_duration_mean = ee.Algorithms.If(\n",
    "            ee.Number(pop_exposed_sum).gt(0),\n",
    "            ee.Number(pop_duration_mask_sum).divide(pop_exposed_sum),\n",
    "            None\n",
    "        )\n",
    "        return ee.Feature(None, {\n",
    "            \"system:index\": sys_id,\n",
    "            \"id\": event_id,\n",
    "            \"Country_code\": ft.get(\"code\"),\n",
    "            \"geo_code\": ft.get(\"get_code2\"),\n",
    "            \"level\": ft.get(\"level\"),\n",
    "            \"GSAP2_mean\": ft.get(\"GSAP2_mean\"),\n",
    "            \"GSAP2_medi\": ft.get(\"GSAP2_medi\"),\n",
    "            \"GSAP2_po_1\": ft.get(\"GSAP2_po_1\"),\n",
    "            \"GSAP2_po_2\": ft.get(\"GSAP2_po_2\"),\n",
    "            \"GSAP2_poor\": ft.get(\"GSAP2_poor\"),\n",
    "            \"GSAP2_gini\": ft.get(\"GSAP2_gini\"),\n",
    "            \"GSAP2_thei\": ft.get(\"GSAP2_thei\"),\n",
    "            \"pop_all\": pop_init_sum,\n",
    "            \"pop_exposed\": pop_exposed_sum,\n",
    "            \"pop_duration_sum\": pop_duration_mask_sum,\n",
    "            \"pop_duration_mean\": pop_duration_mean,\n",
    "            \"Area\": area\n",
    "        })\n",
    "    try:\n",
    "        regions_stats = ee.FeatureCollection(covered_regions_fea_coll).map(get_regions_dura)\n",
    "        regions_stats = ee.FeatureCollection(regions_stats).set({\"id\":event_id})\n",
    "        print(\"calculated results, exporting results for DFO {0}...\".format(int(event_id)))\n",
    "\n",
    "    except Exception as e:\n",
    "        s = str(e)\n",
    "        with open(log_file,\"w\", newline='') as out_file:\n",
    "            wr = csv.writer(out_file)\n",
    "            wr.writerow([\"Calculation Error\", event_id, s])\n",
    "        print(\"Calculation Error {0} - Cataloguing and moving onto next event\".format(event_id))\n",
    "        print(\"-------------------------------------------------\")\n",
    "\n",
    "    # Export results\n",
    "    try:\n",
    "        task = ee.batch.Export.table.toDrive(\n",
    "            collection = regions_stats,\n",
    "            description = 'duration_state_regions_{0}'.format(str(int(event_id))),\n",
    "            bucket = 'regions_stats',\n",
    "            fileNamePrefix = '/Data/GFD/region_duration/duration_state_regions_{0}'.format(str(int(event_id))),\n",
    "            fileFormat = 'CSV')\n",
    "\n",
    "        task.start()\n",
    "\n",
    "    except Exception as e:\n",
    "        s = str(e)\n",
    "        with open(log_file,\"ab\") as out_file:\n",
    "            wr = csv.writer(out_file)\n",
    "            wr.writerow([\"Export Error\", event_id, s])\n",
    "        print(\"Export Error DFO {0} - Cataloguing and moving onto next event\".format(event_id))\n",
    "        print(\"-------------------------------------------------\")\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chongyang Du\n",
    "# Jan 2, 2024\n",
    "\n",
    "# use this template to run the flood stats functions (area, population, etc.)\n",
    "# on an image collection and export results as a .tif\n",
    "\n",
    "import ee\n",
    "import geemap\n",
    "ee.Initialize()\n",
    "\n",
    "# from flood_stats import pop_utils\n",
    "import time, csv\n",
    "\n",
    "def get_flood_pop_pixel(flood_img):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        floodImage : the standard Earth Engine Image object outputted by the map_DFO_event function\n",
    "        roiGEO : the region of interest as an Earth Engine Geometry object\n",
    "\n",
    "    Returns:\n",
    "    -an image of people in the mapped flood from WorldPop data\n",
    "\n",
    "    \"\"\"\n",
    "    import ee\n",
    "    import geemap\n",
    "    ee.Initialize()\n",
    "    # ee.Authenticate()\n",
    "    roi_geo = flood_img.geometry()\n",
    "\n",
    "    # Import the LandScan image collection & permannt water mask\n",
    "    perm_water = ee.Image(\"JRC/GSW1_0/GlobalSurfaceWater\").select(\"transition\").eq(1).unmask()\n",
    "    # print('Band names:', flood_img.bandNames().getInfo())\n",
    "    def maskImages(img):\n",
    "        non_flood = img.select(\"flooded\")\n",
    "        water_mask = non_flood.multiply(perm_water.neq(1))\n",
    "        return img.select(\"flooded\").mask(water_mask)\n",
    "\n",
    "    def durationImages(img):\n",
    "            non_flood = img.select(\"flooded\")\n",
    "            water_mask = non_flood.multiply(perm_water.neq(1))\n",
    "            return img.select(\"duration\").mask(water_mask)\n",
    "\n",
    "    # Extract the final flood extent image data as its own variable for analysis\n",
    "    # flood_extent = maskImages(ee.Image(flood_img.select(\"flooded\")))\n",
    "    # flood_duration = durationImages(ee.Image(flood_img.select(\"flood_duration\")))\n",
    "    flood_extent = maskImages(ee.Image(flood_img))\n",
    "    flood_duration = durationImages(ee.Image(flood_img))\n",
    "\n",
    "\n",
    "    # # get pop from projects/global-flood-db/landscan\n",
    "    # # Get event year, match with the population year and clip to study are\n",
    "    # pop_all = ee.ImageCollection(\"projects/global-flood-db/landscan\")\n",
    "    # event_year = ee.Date(flood_img.get('began')).get('year')\n",
    "    # pop_img = ee.Image(pop_all.filterMetadata('year', 'equals', event_year)\\\n",
    "    #                 .first()).clip(roi_geo)\n",
    "    # pop_img = pop_img.updateMask(pop_img.gte(0)) # mask out bad data with negative values\n",
    "\n",
    "    # get pop from JRC/GHSL/P2016/POP_GPW_GLOBE_V1\n",
    "    pop_all = ee.ImageCollection(\"JRC/GHSL/P2016/POP_GPW_GLOBE_V1\")\n",
    "    # Get event year to match with the population year\n",
    "    # pop_img = ee.Image(pop_all.filterMetadata('system:index', 'equals', '2000')\\\n",
    "    #                 .first()).clip(roi_geo)\n",
    "    pop_img = ee.Image(pop_all.filterMetadata('system:index', 'equals', '2015')\\\n",
    "                    .first()).clip(roi_geo)\n",
    "\n",
    "\n",
    "    # Mask the world population dataset using the flood extent layer\n",
    "    pop_masked = pop_img.updateMask(flood_extent)\n",
    "\n",
    "    pop_duration = pop_masked.multiply(flood_duration)\n",
    "    return flood_extent, flood_duration, pop_img, pop_masked, pop_duration\n",
    "\n",
    "\n",
    "\n",
    "# Image Collection of flood maps, each needs layer called \"flooded\" that\n",
    "# is 1 = flooded, 0 = not flooded\n",
    "gfd = ee.ImageCollection('projects/global-flood-db/gfd_v3')\n",
    "# gfd = ee.ImageCollection('projects/global-flood-db/gfd_v3').filterMetadata('id','greater_than',4335)\n",
    "\n",
    "# Create Error Log file\n",
    "log_file = \"error_logs/event_stats/pop_error_log_{0}.csv\".format(time.strftime(\"%d_%m_%Y\"))\n",
    "with open(log_file,\"w\", newline='') as out_file:\n",
    "    wr = csv.writer(out_file)\n",
    "    wr.writerow([\"error_type\", \"dfo_id\", \"error_message\"])\n",
    "\n",
    "# Create list of events from input fusion table\n",
    "event_ids = ee.List(gfd.aggregate_array('id')).sort()\n",
    "id_list = event_ids.getInfo()\n",
    "id_list = [int(i) for i in id_list]\n",
    "\n",
    "# for event_id in id_list:\n",
    "# event_id = id_list[0]\n",
    "event_id = 4444\n",
    "# Get event date range, they can be passed as Strings\n",
    "flood_event = ee.Image(gfd.filterMetadata('id', 'equals', event_id).first())\n",
    "\n",
    "# try:\n",
    "# Calculate flood stats\n",
    "# flood_stats = pop_utils.getFloodPopbyCountry_GHSLTimeSeries(flood_event)\n",
    "flood_extent, flood_duration, pop_img, pop_masked, pop_duration = get_flood_pop_pixel(flood_event)\n",
    "# index = flood_stats.get(\"id\").getInfo()\n",
    "print(\"calculated results, exporting results for DFO {0}...\".format(event_id))\n",
    "\n",
    "# 定义感兴趣的区域\n",
    "region = pop_img.geometry()\n",
    "\n",
    "# 设置下载参数\n",
    "output_dir = '/download/'\n",
    "scale = pop_img.projection().nominalScale()  # 设置所需的空间分辨率\n",
    "file_format = 'GeoTIFF'  # 设置所需的文件格式\n",
    "\n",
    "# 下载图像集合\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/flooded_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(flood_extent, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/flood_duration_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(flood_duration, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/pop_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(pop_img, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/pop_flooded_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(pop_masked, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/pop_duration_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(pop_duration, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite_flooding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
