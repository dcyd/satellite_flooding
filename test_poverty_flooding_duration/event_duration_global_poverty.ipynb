{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFD中每个灾害事件的duration和不平等性\n",
    "Chongyang Du, Jan 9, 2024\n",
    "\n",
    "\n",
    "首先识别每个灾害事件覆盖的子行政单元\n",
    "生成每个行政单元在此次灾害事件下的duration(暴露人群人均duration)\n",
    "\n",
    "分析人均duration和人均收入或消费之间的相关性，期待的结论：duration越长的地区，越贫困的地区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=bD74uOHnjrxv3dWN2Ix6e5yvkrNbzhmR-0VJhg_KCJ4&tc=tG2yvUeMdXMF2gJmW_4deN6CUU4dUR_M88GPuu3GqN8&cc=zPaJTg_iOQ4NO05roz7avJHp3ewWKjkqi2gDrninIjE>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=bD74uOHnjrxv3dWN2Ix6e5yvkrNbzhmR-0VJhg_KCJ4&tc=tG2yvUeMdXMF2gJmW_4deN6CUU4dUR_M88GPuu3GqN8&cc=zPaJTg_iOQ4NO05roz7avJHp3ewWKjkqi2gDrninIjE</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GFD上所有洪涝事件的ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chongyang Du\n",
    "# Jan 2, 2024\n",
    "\n",
    "# use this template to run the flood stats functions (area, population, etc.)\n",
    "# on an image collection and export results as a .tif\n",
    "\n",
    "import ee\n",
    "import geemap\n",
    "ee.Initialize()\n",
    "\n",
    "# from flood_stats import pop_utils\n",
    "import time, csv\n",
    "\n",
    "def get_flood_pop_pixel(flood_img):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        floodImage : the standard Earth Engine Image object outputted by the map_DFO_event function\n",
    "        roiGEO : the region of interest as an Earth Engine Geometry object\n",
    "\n",
    "    Returns:\n",
    "    -an image of people in the mapped flood from WorldPop data\n",
    "\n",
    "    \"\"\"\n",
    "    import ee\n",
    "    import geemap\n",
    "    ee.Initialize()\n",
    "    # ee.Authenticate()\n",
    "    roi_geo = flood_img.geometry()\n",
    "\n",
    "    # Import the LandScan image collection & permannt water mask\n",
    "    perm_water = ee.Image(\"JRC/GSW1_0/GlobalSurfaceWater\").select(\"transition\").eq(1).unmask()\n",
    "    # print('Band names:', flood_img.bandNames().getInfo())\n",
    "    def maskImages(img):\n",
    "        non_flood = img.select(\"flooded\")\n",
    "        water_mask = non_flood.multiply(perm_water.neq(1))\n",
    "        return img.select(\"flooded\").mask(water_mask)\n",
    "\n",
    "    def durationImages(img):\n",
    "            non_flood = img.select(\"flooded\")\n",
    "            water_mask = non_flood.multiply(perm_water.neq(1))\n",
    "            return img.select(\"duration\").mask(water_mask)\n",
    "\n",
    "    # Extract the final flood extent image data as its own variable for analysis\n",
    "    # flood_extent = maskImages(ee.Image(flood_img.select(\"flooded\")))\n",
    "    # flood_duration = durationImages(ee.Image(flood_img.select(\"flood_duration\")))\n",
    "    flood_extent = maskImages(ee.Image(flood_img))\n",
    "    flood_duration = durationImages(ee.Image(flood_img))\n",
    "\n",
    "\n",
    "    # # get pop from projects/global-flood-db/landscan\n",
    "    # # Get event year, match with the population year and clip to study are\n",
    "    # pop_all = ee.ImageCollection(\"projects/global-flood-db/landscan\")\n",
    "    # event_year = ee.Date(flood_img.get('began')).get('year')\n",
    "    # pop_img = ee.Image(pop_all.filterMetadata('year', 'equals', event_year)\\\n",
    "    #                 .first()).clip(roi_geo)\n",
    "    # pop_img = pop_img.updateMask(pop_img.gte(0)) # mask out bad data with negative values\n",
    "\n",
    "    # get pop from JRC/GHSL/P2016/POP_GPW_GLOBE_V1\n",
    "    pop_all = ee.ImageCollection(\"JRC/GHSL/P2016/POP_GPW_GLOBE_V1\")\n",
    "    # Get event year to match with the population year\n",
    "    # pop_img = ee.Image(pop_all.filterMetadata('system:index', 'equals', '2000')\\\n",
    "    #                 .first()).clip(roi_geo)\n",
    "    pop_img = ee.Image(pop_all.filterMetadata('system:index', 'equals', '2015')\\\n",
    "                    .first()).clip(roi_geo)\n",
    "\n",
    "\n",
    "    # Mask the world population dataset using the flood extent layer\n",
    "    pop_masked = pop_img.updateMask(flood_extent)\n",
    "\n",
    "    pop_duration = pop_masked.multiply(flood_duration)\n",
    "    return flood_extent, flood_duration, pop_img, pop_masked, pop_duration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913\n"
     ]
    }
   ],
   "source": [
    "# identify the administrative region covered by each flood event\n",
    "import ee\n",
    "ee.Initialize()\n",
    "\n",
    "import time, csv\n",
    "# from flood_stats import pop_utils\n",
    "\n",
    "# Image Collection of flood maps, each needs layer called \"flooded\" that\n",
    "# is 1 = flooded, 0 = not flooded\n",
    "gfd = ee.ImageCollection('projects/global-flood-db/gfd_v3').filterMetadata('id','greater_than',1).filterMetadata('id','less_than',5000)\n",
    "# 1-2500; 2500-3000 3500-5000\n",
    "# gfd = ee.ImageCollection('projects/global-flood-db/gfd_v3').filterMetadata('id','greater_than',4710)\n",
    "\n",
    "# greater_than\n",
    "# 1500\n",
    "# Create Error Log file\n",
    "log_file = \"../error_logs/event_stats/pop_error_log_{0}.csv\".format(time.strftime(\"%d_%m_%Y\"))\n",
    "with open(log_file,\"w\", newline='') as out_file:\n",
    "    wr = csv.writer(out_file)\n",
    "    wr.writerow([\"error_type\", \"dfo_id\", \"error_message\"])\n",
    "\n",
    "# Create list of events from input fusion table\n",
    "event_ids = ee.List(gfd.aggregate_array('id')).sort()\n",
    "id_list = event_ids.getInfo()\n",
    "id_list = [int(i) for i in id_list]\n",
    "print(len(id_list))\n",
    "# print(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dfo_centroid_y': -31.268059, 'dfo_main_cause': 'Monsoonal rain', 'gfd_country_name': \"['AUSTRALIA']\", 'dfo_centroid_x': 143.6978, 'glide_index': 'NA', 'slope_threshold': 5, 'dfo_severity': 2, 'system:footprint': {'type': 'LinearRing', 'coordinates': [[139.6005812730815, -17.518267010104264], [138.4040674236775, -17.51707155596811], [137.20519449393421, -17.518262275331107], [137.20471106885168, -37.68095660034486], [139.99941925183816, -37.680961429261664], [141.9936089883675, -37.680961430234674], [143.98779872401195, -37.680961424329006], [145.58315055189232, -37.68096143983046], [147.97617824298896, -37.680961381848334], [149.97321059715983, -37.68095662726775], [149.97272709473495, -17.518262280872825], [148.77385413322452, -17.51707158835981], [147.57734028086537, -17.518267026312603], [146.38082649061207, -17.517071608501123], [145.18431256933783, -17.518267014811364], [143.98779872401195, -17.51707157652277], [142.39244698359286, -17.51707158759303], [140.79709518683185, -17.517071570794638], [139.6005812730815, -17.518267010104264]]}, 'threshold_b1b2': 0.711, 'otsu_sample_res': 231.66, 'dfo_displaced': 200, 'id': 1586, 'cc': 'AUS', 'began': '2000-02-18', 'dfo_validation_type': 'News', 'composite_type': '3Day', 'dfo_country': 'Australia', 'countries': 'Australia', 'dfo_other_country': 'NA', 'dfo_dead': 1, 'gfd_country_code': \"['AS']\", 'ended': '2000-03-01', 'threshold_type': 'otsu', 'threshold_b7': 1815.18, 'system:asset_size': 8987006, 'system:index': 'DFO_1586_From_20000218_to_20000301'}\n",
      "dict_keys(['dfo_centroid_y', 'dfo_main_cause', 'gfd_country_name', 'dfo_centroid_x', 'glide_index', 'slope_threshold', 'dfo_severity', 'system:footprint', 'threshold_b1b2', 'otsu_sample_res', 'dfo_displaced', 'id', 'cc', 'began', 'dfo_validation_type', 'composite_type', 'dfo_country', 'countries', 'dfo_other_country', 'dfo_dead', 'gfd_country_code', 'ended', 'threshold_type', 'threshold_b7', 'system:asset_size', 'system:index'])\n",
      "AUS\n"
     ]
    }
   ],
   "source": [
    "first_image = gfd.first()\n",
    "\n",
    "# Retrieve information about the first image as a dictionary.\n",
    "first_image_info = first_image.getInfo()\n",
    "\n",
    "# Now you can print or inspect 'first_image_info' to see all properties.\n",
    "print(first_image_info['properties'])\n",
    "\n",
    "# If you want to see all property names (keys) of the first image:\n",
    "property_names = first_image_info['properties'].keys()\n",
    "print(property_names)\n",
    "\n",
    "print(first_image_info['properties']['cc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对每个洪涝灾害，识别覆盖的行政单元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFO 4673 is in BGD, IND, CHN, NPL\n",
      "found 27 regions covered by the flood event\n",
      "calculated results for DFO 4673...\n",
      "Exporting FeatureCollection to CSV..._4673\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "# Load the shapefile\n",
    "\n",
    "gdf = ee.FeatureCollection(\"projects/ee-dcy0910/assets/GSAP2\")\n",
    "\n",
    "# # Convert GeoSeries to list of shapely geometries\n",
    "# gdf['geometry'] = gdf['geometry'].apply(lambda x: shape(x))\n",
    "# id_list = [2753]\n",
    "all_regions_stats_ge = []  # List to store regions_stats of each event\n",
    "all_regions_stats = []\n",
    "id_list = [4673]\n",
    "for event_id in id_list:\n",
    "    # Get event date range, they can be passed as Strings\n",
    "    flood_event = ee.Image(gfd.filterMetadata('id', 'equals', event_id).first())\n",
    "    flood_event_info = flood_event.getInfo()\n",
    "    # print(flood_event_info['properties']['gfd_country_name'])\n",
    "    if event_id == 2117:\n",
    "        flood_event_info['properties']['cc'] = 'PRT, ESP, GIB, FRA, AND, ITA, MCO, UKR, ROU, POL, DEU, CZE, AUT, CHE, LIE, LUX, NLD, BEL, JEY, GGY'\n",
    "    elif event_id == 3145:\n",
    "        flood_event_info['properties']['cc'] = 'MLI, BFA'\n",
    "    elif event_id == 3494:\n",
    "        flood_event_info['properties']['cc'] = 'THA, CHN, LAO, KHM, VNM'\n",
    "    elif event_id == 4009:\n",
    "        flood_event_info['properties']['cc'] = 'GBR, IMN'\n",
    "    elif event_id == 4111:\n",
    "        flood_event_info['properties']['cc'] = 'GBR, IMN, IRL'\n",
    "    elif event_id == 4319:\n",
    "        flood_event_info['properties']['cc'] = 'GBR, IRL, IMN'\n",
    "    elif event_id == 4632:\n",
    "        flood_event_info['properties']['cc'] = 'THA, MMR, BGD, IND, CHN'\n",
    "    elif event_id == 4640:\n",
    "        flood_event_info['properties']['cc'] = 'IND, CHN, PAK, NPL'\n",
    "    elif event_id == 4645:\n",
    "        flood_event_info['properties']['cc'] = 'IND, CHN, AFG, PAK, NPL'\n",
    "    elif event_id == 4652:\n",
    "        flood_event_info['properties']['cc'] = 'THA, MMR, LAO, KHM, VNM'\n",
    "    elif event_id == 4653:\n",
    "        flood_event_info['properties']['cc'] = 'CHN, LAO, KHM, VNM'\n",
    "    elif event_id == 4654:\n",
    "        flood_event_info['properties']['cc'] = 'CHN, KAZ, RUS, MNG'\n",
    "    elif event_id == 4662:\n",
    "        flood_event_info['properties']['cc'] = 'BRA, VEN, GUY, COL'\n",
    "    elif event_id == 4665:\n",
    "        flood_event_info['properties']['cc'] = 'MMR, BGD, IND, CHN, BTN, NPL'\n",
    "    elif event_id == 4666:\n",
    "        flood_event_info['properties']['cc'] = 'MMR, BGD, IND, CHN'\n",
    "    elif event_id == 4667:\n",
    "        flood_event_info['properties']['cc'] = 'BEN, NGA, CMR, TCD, NER'\n",
    "    elif event_id == 4673:\n",
    "        flood_event_info['properties']['cc'] = 'BGD, IND, CHN, NPL'\n",
    "    elif event_id == 4676:\n",
    "        flood_event_info['properties']['cc'] = 'USA'\n",
    "    elif event_id == 4683:\n",
    "        flood_event_info['properties']['cc'] = 'BFA, TGO, GHA, CIV, BEN'\n",
    "    elif event_id == 4695:\n",
    "        flood_event_info['properties']['cc'] = 'USA, MEX'\n",
    "    elif event_id == 4703:\n",
    "        flood_event_info['properties']['cc'] = 'BRA, BOL, PRY, ARG'\n",
    "    elif event_id == 4704:\n",
    "        flood_event_info['properties']['cc'] = 'THA, LAO, KHM, VNM'\n",
    "    elif event_id == 4711:\n",
    "        flood_event_info['properties']['cc'] = 'USA, MEX'\n",
    "\n",
    "    # Check if 'cc' exists in the properties\n",
    "    if 'cc' in flood_event_info['properties']:\n",
    "        event_coun_code = flood_event_info['properties']['cc']\n",
    "        print(\"DFO {0} is in {1}\".format(event_id, event_coun_code))\n",
    "    else:\n",
    "        # 'cc' not found, so print 'gfd_country_name' and event_id\n",
    "        gfd_country_name = flood_event_info['properties'].get('gfd_country_name', 'Unknown Country Name')\n",
    "        print(\"Property 'cc' not found for event ID {}. Country: {}\".format(event_id, gfd_country_name))\n",
    "    \n",
    "    country_codes_list = event_coun_code.split(', ')\n",
    "\n",
    "    # try:\n",
    "    # Calculate flood stats\n",
    "    # flood_stats = pop_utils.getFloodPopbyCountry_GHSLTimeSeries(flood_event)\n",
    "    flood_extent, flood_duration, pop_img, pop_masked, pop_duration = get_flood_pop_pixel(flood_event)\n",
    "\n",
    "    # Filter the regions covered by the flood event\n",
    "    # gdf_coun = gdf[gdf['code'].isin(country_codes_list)]\n",
    "    gdf_coun = gdf.filter(ee.Filter.inList('code', ee.List(country_codes_list)))\n",
    "\n",
    "    covered_regions = gdf_coun.filterBounds(flood_extent.geometry())\n",
    "    numberOfRegions = covered_regions.size()\n",
    "\n",
    "    # Use getInfo() to retrieve the number and print it\n",
    "    print(\"found {} regions covered by the flood event\".format(numberOfRegions.getInfo()))\n",
    "\n",
    "    covered_regions_fea_coll = covered_regions\n",
    "    # Get area of flood in the scale of the flood map\n",
    "    flood_area_img = flood_extent.multiply(ee.Image.pixelArea())\n",
    "    map_scale = flood_extent.projection().nominalScale()\n",
    "    \n",
    "    pop_scale = pop_img.projection().nominalScale()\n",
    "\n",
    "    pop_masked_scale = pop_masked.projection().nominalScale()\n",
    "\n",
    "    pop_duration_scale = pop_duration.projection().nominalScale()\n",
    "\n",
    "    def get_regions_dura_ge(ft):\n",
    "        '''\n",
    "        This function calculates the population exposure and duration of each flood event\n",
    "        for each administrative region covered by the flood event\n",
    "        Input: ft - a feature from the feature collection of covered regions\n",
    "        '''\n",
    "\n",
    "        # Initialize a dictionary with all required properties set to None\n",
    "        properties = {\n",
    "            \"eveId\": None, \"eveBegan\": None, \"geoCounCo\": None, \n",
    "            \"geoCode\": None, \"geoLevel\": None, \"incoMean\": None, \n",
    "            \"incoMedi\": None, \"incoGini\": None, \"incoThei\": None,\n",
    "            \"poor215\": None, \"poor365\": None, \"poor685\": None, \n",
    "            \"popAll\": None, \"popExposed\": None, \"durPopSum\": None, \n",
    "            \"durPopMean\": None, \"durCelMean\": None, \"durCelMax\": None,\n",
    "        }\n",
    "\n",
    "        pop_sum = pop_img.reduceRegion(\n",
    "        reducer = ee.Reducer.sum(),\n",
    "        geometry = ft.geometry(),\n",
    "        scale = pop_scale,\n",
    "        maxPixels = 1e9)\n",
    "\n",
    "        area_sum= flood_area_img.reduceRegion(\n",
    "        reducer= ee.Reducer.sum(),\n",
    "        geometry= ft.geometry(),\n",
    "        scale= map_scale,\n",
    "        maxPixels= 1e9)\n",
    "\n",
    "        pop_exposed= pop_masked.reduceRegion(\n",
    "        reducer= ee.Reducer.sum(),\n",
    "        geometry= ft.geometry(),\n",
    "        scale= pop_masked_scale,\n",
    "        maxPixels= 1e9)\n",
    "\n",
    "        pop_duration_mask = pop_duration.reduceRegion(\n",
    "        reducer= ee.Reducer.sum(),\n",
    "        geometry= ft.geometry(),\n",
    "        scale= pop_duration_scale,\n",
    "        maxPixels= 1e9)\n",
    "\n",
    "        duration_mean_mask = flood_duration.reduceRegion(\n",
    "        reducer= ee.Reducer.mean(),\n",
    "        geometry= ft.geometry(),\n",
    "        scale= map_scale,\n",
    "        maxPixels= 1e9)\n",
    "\n",
    "        duration_max_mask = flood_duration.reduceRegion(\n",
    "        reducer= ee.Reducer.max(),\n",
    "        geometry= ft.geometry(),\n",
    "        scale= map_scale,\n",
    "        maxPixels= 1e9)\n",
    "\n",
    "        def format_number(number):\n",
    "            return ee.Number(number).format('%.2f')\n",
    "\n",
    "        pop_init_sum = format_number(pop_sum.get(\"population_count\"))\n",
    "        pop_exposed_sum = pop_exposed.get(\"population_count\")\n",
    "        pop_duration_mask_sum = pop_duration_mask.get(\"population_count\")\n",
    "\n",
    "        # Calculate the ratio of pop_duration_mask_sum to pop_exposed_sum\n",
    "        # Ensure that pop_exposed_sum is not zero to avoid division by zero error\n",
    "\n",
    "        duration_pop_mean = ee.Algorithms.If(\n",
    "            ee.Number(pop_exposed_sum).gt(0),\n",
    "            format_number(ee.Number(pop_duration_mask_sum).divide(pop_exposed_sum)),\n",
    "            ''\n",
    "        )\n",
    "        pop_exposed_sum = format_number(pop_exposed.get(\"population_count\"))\n",
    "\n",
    "        duration_pop_sum = ee.Algorithms.If(\n",
    "            pop_duration_mask_sum,\n",
    "            format_number(pop_duration_mask_sum),\n",
    "            ''  # Use -1 to represent None\n",
    "        )\n",
    "        duration_cell_mean = ee.Algorithms.If(\n",
    "            duration_mean_mask.get(\"duration\"),\n",
    "            format_number(ee.Number(duration_mean_mask.get(\"duration\"))),\n",
    "            ''  # Use -1 to represent None\n",
    "        )\n",
    "\n",
    "        duration_cell_max = ee.Algorithms.If(\n",
    "            duration_max_mask.get(\"duration\"),\n",
    "            format_number(ee.Number(duration_max_mask.get(\"duration\"))),\n",
    "            ''  # Use -1 to represent None\n",
    "        )\n",
    "        income_mean = ee.Algorithms.If(\n",
    "            ft.get(\"GSAP2_mean\"),\n",
    "            ee.Number.parse(ft.get(\"GSAP2_mean\")).format('%.2f'),\n",
    "            ''  # Use -1 to represent None\n",
    "            )\n",
    "        income_medi = ee.Algorithms.If(\n",
    "            ft.get(\"GSAP2_medi\"),\n",
    "            ee.Number.parse(ft.get(\"GSAP2_medi\")).format('%.2f'),\n",
    "            ''  # Use -1 to represent None\n",
    "            )\n",
    "        income_gini = ee.Algorithms.If(\n",
    "            ft.get(\"GSAP2_gini\"),\n",
    "            ee.Number.parse(ft.get(\"GSAP2_gini\")).format('%.2f'),\n",
    "            ''  # Use -1 to represent None\n",
    "            )\n",
    "        income_thei = ee.Algorithms.If(\n",
    "            ft.get(\"GSAP2_thei\"),\n",
    "            ee.Number.parse(ft.get(\"GSAP2_thei\")).format('%.2f'),\n",
    "            ''  # Use -1 to represent None\n",
    "            )\n",
    "\n",
    "        # Update the dictionary with actual values from calculations\n",
    "        properties.update({\n",
    "            \"eveId\": event_id,\n",
    "            \"eveBegan\": flood_event.get(\"began\"),\n",
    "            \"geoCounCo\": ft.get(\"code\"),\n",
    "            \"geoCode\": ft.get(\"geo_code2\"),\n",
    "            \"geoLevel\": ft.get(\"level\"),\n",
    "            \"incoMean\": income_mean,\n",
    "            \"incoMedi\": income_medi,\n",
    "            \"incoGini\": income_gini,\n",
    "            \"incoThei\": income_thei,\n",
    "            \"poor215\": ft.get(\"GSAP2_poor\"),\n",
    "            \"poor365\": ft.get(\"GSAP2_po_1\"),\n",
    "            \"poor685\": ft.get(\"GSAP2_po_2\"),\n",
    "            \"popAll\": pop_init_sum,\n",
    "            \"popExposed\": pop_exposed_sum,\n",
    "            \"durPopSum\": duration_pop_sum,\n",
    "            \"durPopMean\": duration_pop_mean,\n",
    "            \"durCelMean\": duration_cell_mean,\n",
    "            \"durCelMax\": duration_cell_max,\n",
    "        })\n",
    "\n",
    "        return ee.Feature(ft.geometry(), properties)\n",
    "    \n",
    "    def get_regions_dura(ft):\n",
    "        '''\n",
    "        This function calculates the population exposure and duration of each flood event\n",
    "        for each administrative region covered by the flood event\n",
    "        Input: ft - a feature from the feature collection of covered regions\n",
    "        '''\n",
    "        # Initialize a dictionary with all required properties set to None\n",
    "        properties = {\n",
    "            \"eveId\": None, \"eveBegan\": None, \"geoCounCo\": None, \n",
    "            \"geoCode\": None, \"geoLevel\": None, \"incoMean\": None, \n",
    "            \"incoMedi\": None, \"incoGini\": None, \"incoThei\": None,\n",
    "            \"poor215\": None, \"poor365\": None, \"poor685\": None, \n",
    "            \"popAll\": None, \"popExposed\": None, \"durPopSum\": None, \n",
    "            \"durPopMean\": None, \"durCelMean\": None, \"durCelMax\": None,\n",
    "        }\n",
    "\n",
    "        pop_sum = pop_img.reduceRegion(\n",
    "        reducer = ee.Reducer.sum(),\n",
    "        geometry = ft.geometry(),\n",
    "        scale = pop_scale,\n",
    "        maxPixels = 1e9)\n",
    "\n",
    "        area_sum= flood_area_img.reduceRegion(\n",
    "        reducer= ee.Reducer.sum(),\n",
    "        geometry= ft.geometry(),\n",
    "        scale= map_scale,\n",
    "        maxPixels= 1e9)\n",
    "\n",
    "        pop_exposed= pop_masked.reduceRegion(\n",
    "        reducer= ee.Reducer.sum(),\n",
    "        geometry= ft.geometry(),\n",
    "        scale= pop_masked_scale,\n",
    "        maxPixels= 1e9)\n",
    "\n",
    "        pop_duration_mask = pop_duration.reduceRegion(\n",
    "        reducer= ee.Reducer.sum(),\n",
    "        geometry= ft.geometry(),\n",
    "        scale= pop_duration_scale,\n",
    "        maxPixels= 1e9)\n",
    "\n",
    "        duration_mean_mask = flood_duration.reduceRegion(\n",
    "        reducer= ee.Reducer.mean(),\n",
    "        geometry= ft.geometry(),\n",
    "        scale= map_scale,\n",
    "        maxPixels= 1e9)\n",
    "\n",
    "        duration_max_mask = flood_duration.reduceRegion(\n",
    "        reducer= ee.Reducer.max(),\n",
    "        geometry= ft.geometry(),\n",
    "        scale= map_scale,\n",
    "        maxPixels= 1e9)\n",
    "\n",
    "        def format_number(number):\n",
    "            return ee.Number(number).format('%.2f')\n",
    "\n",
    "        pop_init_sum = format_number(pop_sum.get(\"population_count\"))\n",
    "        pop_exposed_sum = pop_exposed.get(\"population_count\")\n",
    "        pop_duration_mask_sum = pop_duration_mask.get(\"population_count\")\n",
    "\n",
    "        # Calculate the ratio of pop_duration_mask_sum to pop_exposed_sum\n",
    "        # Ensure that pop_exposed_sum is not zero to avoid division by zero error\n",
    "\n",
    "        duration_pop_mean = ee.Algorithms.If(\n",
    "            ee.Number(pop_exposed_sum).gt(0),\n",
    "            format_number(ee.Number(pop_duration_mask_sum).divide(pop_exposed_sum)),\n",
    "            ''\n",
    "        )\n",
    "        pop_exposed_sum = format_number(pop_exposed.get(\"population_count\"))\n",
    "\n",
    "        duration_pop_sum = ee.Algorithms.If(\n",
    "            pop_duration_mask_sum,\n",
    "            format_number(pop_duration_mask_sum),\n",
    "            ''  # Use -1 to represent None\n",
    "        )\n",
    "        # duration_cell_mean = duration_mean_mask.get(\"duration\")\n",
    "        # duration_cell_max = duration_max_mask.get(\"duration\")\n",
    "        duration_cell_mean = ee.Algorithms.If(\n",
    "            duration_mean_mask.get(\"duration\"),\n",
    "            format_number(ee.Number(duration_mean_mask.get(\"duration\"))),\n",
    "            ''  # Use -1 to represent None\n",
    "        )\n",
    "\n",
    "        duration_cell_max = ee.Algorithms.If(\n",
    "            duration_max_mask.get(\"duration\"),\n",
    "            format_number(ee.Number(duration_max_mask.get(\"duration\"))),\n",
    "            ''  # Use -1 to represent None\n",
    "        )\n",
    "        income_mean = ee.Algorithms.If(\n",
    "            ft.get(\"GSAP2_mean\"),\n",
    "            ee.Number.parse(ft.get(\"GSAP2_mean\")).format('%.2f'),\n",
    "            ''  # Use -1 to represent None\n",
    "            )\n",
    "        income_medi = ee.Algorithms.If(\n",
    "            ft.get(\"GSAP2_medi\"),\n",
    "            ee.Number.parse(ft.get(\"GSAP2_medi\")).format('%.2f'),\n",
    "            ''  # Use -1 to represent None\n",
    "            )\n",
    "        income_gini = ee.Algorithms.If(\n",
    "            ft.get(\"GSAP2_gini\"),\n",
    "            ee.Number.parse(ft.get(\"GSAP2_gini\")).format('%.2f'),\n",
    "            ''  # Use -1 to represent None\n",
    "            )\n",
    "        income_thei = ee.Algorithms.If(\n",
    "            ft.get(\"GSAP2_thei\"),\n",
    "            ee.Number.parse(ft.get(\"GSAP2_thei\")).format('%.2f'),\n",
    "            ''  # Use -1 to represent None\n",
    "            )\n",
    "\n",
    "        # Update the dictionary with actual values from calculations\n",
    "        properties.update({\n",
    "            \"eveId\": event_id,\n",
    "            \"eveBegan\": flood_event.get(\"began\"),\n",
    "            \"geoCounCo\": ft.get(\"code\"),\n",
    "            \"geoCode\": ft.get(\"geo_code2\"),\n",
    "            \"geoLevel\": ft.get(\"level\"),\n",
    "            \"incoMean\": income_mean,\n",
    "            \"incoMedi\": income_medi,\n",
    "            \"incoGini\": income_gini,\n",
    "            \"incoThei\": income_thei,\n",
    "            \"poor215\": ft.get(\"GSAP2_poor\"),\n",
    "            \"poor365\": ft.get(\"GSAP2_po_1\"),\n",
    "            \"poor685\": ft.get(\"GSAP2_po_2\"),\n",
    "            \"popAll\": pop_init_sum,\n",
    "            \"popExposed\": pop_exposed_sum,\n",
    "            \"durPopSum\": duration_pop_sum,\n",
    "            \"durPopMean\": duration_pop_mean,\n",
    "            \"durCelMean\": duration_cell_mean,\n",
    "            \"durCelMax\": duration_cell_max,\n",
    "        })\n",
    "    \n",
    "        return ee.Feature(None, properties)\n",
    "        \n",
    "    try:\n",
    "        regions_stats_ge = ee.FeatureCollection(covered_regions_fea_coll).map(get_regions_dura_ge)\n",
    "        regions_stats = ee.FeatureCollection(covered_regions_fea_coll).map(get_regions_dura)\n",
    "        # regions_stats = ee.FeatureCollection(regions_stats).set({\"id\":event_id})\n",
    "        print(\"calculated results for DFO {0}...\".format(int(event_id)))\n",
    "        # print(regions_stats.first().getInfo())\n",
    "        # Append regions_stats to the list\n",
    "        all_regions_stats.append(regions_stats)\n",
    "        all_regions_stats_ge.append(regions_stats_ge)\n",
    "    except Exception as e:\n",
    "        s = str(e)\n",
    "        with open(log_file,\"w\", newline='') as out_file:\n",
    "            wr = csv.writer(out_file)\n",
    "            wr.writerow([\"Calculation Error\", event_id, s])\n",
    "        print(\"Calculation Error {0} - Cataloguing and moving onto next event\".format(event_id))\n",
    "        print(s)\n",
    "        print(\"-------------------------------------------------\")\n",
    "\n",
    "    # Export results\n",
    "    try:\n",
    "        print(\"Exporting FeatureCollection to CSV..._{0}\".format(str(int(event_id))))\n",
    "        task = ee.batch.Export.table.toDrive(\n",
    "            collection = regions_stats,\n",
    "            description = 'csv for duration_state_regions_{0}'.format(str(int(event_id))),\n",
    "            folder='GFD_region_duration_csv',\n",
    "            fileNamePrefix = 'duration_state_regions_{0}'.format(str(int(event_id))),\n",
    "            fileFormat = 'CSV')\n",
    "        task.start()\n",
    "    except Exception as e:\n",
    "        s = str(e)\n",
    "        with open(log_file,\"ab\") as out_file:\n",
    "            wr = csv.writer(out_file)\n",
    "            wr.writerow([\"Export Error\", event_id, s])\n",
    "        print(\"Export Error DFO {0} - Cataloguing and moving onto next event\".format(event_id))\n",
    "        print(\"-------------------------------------------------\")\n",
    "\n",
    "    # try:\n",
    "    #     # collection = regions_stats_ge,\n",
    "    #     print(\"Exporting FeatureCollection to SHP..._{0}\".format(str(int(event_id))))\n",
    "    #     def addGeometryType(feature):\n",
    "    #         geomType = feature.geometry().type()\n",
    "    #         return feature.set('geomType', geomType)\n",
    "    #     regions_stats_ge = regions_stats_ge.map(addGeometryType)\n",
    "    #     regions_stats_ge = regions_stats_ge.filter(ee.Filter.eq('geomType', 'Polygon'))\n",
    "    #     task = ee.batch.Export.table.toDrive(\n",
    "    #         collection = regions_stats_ge,\n",
    "    #         description = 'shp for duration_state_regions_{0}'.format(str(int(event_id))),\n",
    "    #         folder='GFD_region_duration_shp',\n",
    "    #         fileNamePrefix = 'duration_state_regions_{0}'.format(str(int(event_id))),\n",
    "    #         fileFormat = 'SHP')\n",
    "    #     task.start()\n",
    "    # except Exception as e:\n",
    "    #     s = str(e)\n",
    "    #     with open(log_file,\"ab\") as out_file:\n",
    "    #         wr = csv.writer(out_file)\n",
    "    #         wr.writerow([\"Export Error\", event_id, s])\n",
    "    #     print(\"Export Error DFO {0} - Cataloguing and moving onto next event\".format(event_id))\n",
    "    #     print(\"-------------------------------------------------\")\n",
    "\n",
    "# After the loop, merge all FeatureCollections into one\n",
    "# all_regions_stats_fc = ee.FeatureCollection(all_regions_stats).flatten()\n",
    "# print(all_regions_stats_fc.first().getInfo())\n",
    "# all_regions_stats_ge_fc = ee.FeatureCollection(all_regions_stats_ge).flatten()\n",
    "# # Export the merged FeatureCollection to a CSV\n",
    "# try:\n",
    "#     print(\"Exporting merged FeatureCollection to CSV...\")\n",
    "#     task = ee.batch.Export.table.toDrive(\n",
    "#         collection = all_regions_stats_fc,\n",
    "#         description = 'all_duration_state_regions_csv',\n",
    "#         folder = 'GFD_region_duration_all',\n",
    "#         fileNamePrefix = 'all_duration_state_regions',\n",
    "#         fileFormat = 'CSV')\n",
    "#     task.start()\n",
    "# except Exception as e:\n",
    "#     s = str(e)\n",
    "#     with open(log_file,\"ab\") as out_file:\n",
    "#         wr = csv.writer(out_file)\n",
    "#         wr.writerow([\"Export Error to save all information to one .csv\"])\n",
    "#     print(\"-------------------------------------------------\")\n",
    "\n",
    "# try:\n",
    "#     print(\"Exporting merged FeatureCollection to SHP...\")\n",
    "#     task = ee.batch.Export.table.toDrive(\n",
    "#         collection = all_regions_stats_ge_fc,\n",
    "#         description = 'all_duration_state_regions_shp',\n",
    "#         folder = 'GFD_region_duration_shp',\n",
    "#         fileNamePrefix = 'all_duration_state_regions',\n",
    "#         fileFormat = 'SHP')\n",
    "#     task.start()\n",
    "# except Exception as e:\n",
    "#     s = str(e)\n",
    "#     with open(log_file,\"ab\") as out_file:\n",
    "#         wr = csv.writer(out_file)\n",
    "#         print(e)\n",
    "#         wr.writerow([\"Export Error to save all information to one .shp\", e])\n",
    "#     print(\"-------------------------------------------------\")\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. to one .csv\n",
    "2. visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chongyang Du\n",
    "# Jan 2, 2024\n",
    "\n",
    "# use this template to run the flood stats functions (area, population, etc.)\n",
    "# on an image collection and export results as a .tif\n",
    "\n",
    "import ee\n",
    "import geemap\n",
    "ee.Initialize()\n",
    "\n",
    "# from flood_stats import pop_utils\n",
    "import time, csv\n",
    "\n",
    "def get_flood_pop_pixel(flood_img):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        floodImage : the standard Earth Engine Image object outputted by the map_DFO_event function\n",
    "        roiGEO : the region of interest as an Earth Engine Geometry object\n",
    "\n",
    "    Returns:\n",
    "    -an image of people in the mapped flood from WorldPop data\n",
    "\n",
    "    \"\"\"\n",
    "    import ee\n",
    "    import geemap\n",
    "    ee.Initialize()\n",
    "    # ee.Authenticate()\n",
    "    roi_geo = flood_img.geometry()\n",
    "\n",
    "    # Import the LandScan image collection & permannt water mask\n",
    "    perm_water = ee.Image(\"JRC/GSW1_0/GlobalSurfaceWater\").select(\"transition\").eq(1).unmask()\n",
    "    # print('Band names:', flood_img.bandNames().getInfo())\n",
    "    def maskImages(img):\n",
    "        non_flood = img.select(\"flooded\")\n",
    "        water_mask = non_flood.multiply(perm_water.neq(1))\n",
    "        return img.select(\"flooded\").mask(water_mask)\n",
    "\n",
    "    def durationImages(img):\n",
    "            non_flood = img.select(\"flooded\")\n",
    "            water_mask = non_flood.multiply(perm_water.neq(1))\n",
    "            return img.select(\"duration\").mask(water_mask)\n",
    "\n",
    "    # Extract the final flood extent image data as its own variable for analysis\n",
    "    # flood_extent = maskImages(ee.Image(flood_img.select(\"flooded\")))\n",
    "    # flood_duration = durationImages(ee.Image(flood_img.select(\"flood_duration\")))\n",
    "    flood_extent = maskImages(ee.Image(flood_img))\n",
    "    flood_duration = durationImages(ee.Image(flood_img))\n",
    "\n",
    "\n",
    "    # # get pop from projects/global-flood-db/landscan\n",
    "    # # Get event year, match with the population year and clip to study are\n",
    "    # pop_all = ee.ImageCollection(\"projects/global-flood-db/landscan\")\n",
    "    # event_year = ee.Date(flood_img.get('began')).get('year')\n",
    "    # pop_img = ee.Image(pop_all.filterMetadata('year', 'equals', event_year)\\\n",
    "    #                 .first()).clip(roi_geo)\n",
    "    # pop_img = pop_img.updateMask(pop_img.gte(0)) # mask out bad data with negative values\n",
    "\n",
    "    # get pop from JRC/GHSL/P2016/POP_GPW_GLOBE_V1\n",
    "    pop_all = ee.ImageCollection(\"JRC/GHSL/P2016/POP_GPW_GLOBE_V1\")\n",
    "    # Get event year to match with the population year\n",
    "    # pop_img = ee.Image(pop_all.filterMetadata('system:index', 'equals', '2000')\\\n",
    "    #                 .first()).clip(roi_geo)\n",
    "    pop_img = ee.Image(pop_all.filterMetadata('system:index', 'equals', '2015')\\\n",
    "                    .first()).clip(roi_geo)\n",
    "\n",
    "\n",
    "    # Mask the world population dataset using the flood extent layer\n",
    "    pop_masked = pop_img.updateMask(flood_extent)\n",
    "\n",
    "    pop_duration = pop_masked.multiply(flood_duration)\n",
    "    return flood_extent, flood_duration, pop_img, pop_masked, pop_duration\n",
    "\n",
    "\n",
    "\n",
    "# Image Collection of flood maps, each needs layer called \"flooded\" that\n",
    "# is 1 = flooded, 0 = not flooded\n",
    "gfd = ee.ImageCollection('projects/global-flood-db/gfd_v3')\n",
    "# gfd = ee.ImageCollection('projects/global-flood-db/gfd_v3').filterMetadata('id','greater_than',4335)\n",
    "\n",
    "# Create Error Log file\n",
    "log_file = \"error_logs/event_stats/pop_error_log_{0}.csv\".format(time.strftime(\"%d_%m_%Y\"))\n",
    "with open(log_file,\"w\", newline='') as out_file:\n",
    "    wr = csv.writer(out_file)\n",
    "    wr.writerow([\"error_type\", \"dfo_id\", \"error_message\"])\n",
    "\n",
    "# Create list of events from input fusion table\n",
    "event_ids = ee.List(gfd.aggregate_array('id')).sort()\n",
    "id_list = event_ids.getInfo()\n",
    "id_list = [int(i) for i in id_list]\n",
    "\n",
    "# for event_id in id_list:\n",
    "# event_id = id_list[0]\n",
    "event_id = 4444\n",
    "# Get event date range, they can be passed as Strings\n",
    "flood_event = ee.Image(gfd.filterMetadata('id', 'equals', event_id).first())\n",
    "\n",
    "# try:\n",
    "# Calculate flood stats\n",
    "# flood_stats = pop_utils.getFloodPopbyCountry_GHSLTimeSeries(flood_event)\n",
    "flood_extent, flood_duration, pop_img, pop_masked, pop_duration = get_flood_pop_pixel(flood_event)\n",
    "# index = flood_stats.get(\"id\").getInfo()\n",
    "print(\"calculated results, exporting results for DFO {0}...\".format(event_id))\n",
    "\n",
    "# 定义感兴趣的区域\n",
    "region = pop_img.geometry()\n",
    "\n",
    "# 设置下载参数\n",
    "output_dir = '/download/'\n",
    "scale = pop_img.projection().nominalScale()  # 设置所需的空间分辨率\n",
    "file_format = 'GeoTIFF'  # 设置所需的文件格式\n",
    "\n",
    "# 下载图像集合\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/flooded_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(flood_extent, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/flood_duration_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(flood_duration, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/pop_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(pop_img, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/pop_flooded_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(pop_masked, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/pop_duration_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(pop_duration, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite_flooding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
