{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The factors on the regional duration\n",
    "\n",
    "Chongyang Du, Jan 22, 2024\n",
    "\n",
    "生成一个数据集，每个数据针对一个事件、一个行政区\n",
    "生成表格，每行对应一个事件下一个行政区，包含洪涝信息（）、经济发展信息（）、降雨信息（3\\7\\30天最大累积降雨量）、地貌信息（平均海拔、平均坡度）、渗透信息（平均不透水比例、平均CN）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GFD上所有洪涝事件的ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chongyang Du\n",
    "# Jan 2, 2024\n",
    "\n",
    "# use this template to run the flood stats functions (area, population, etc.)\n",
    "# on an image collection and export results as a .tif\n",
    "\n",
    "import ee\n",
    "import geemap\n",
    "ee.Initialize()\n",
    "\n",
    "# from flood_stats import pop_utils\n",
    "import time, csv\n",
    "\n",
    "def get_flood_pop_pixel(flood_img):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        floodImage : the standard Earth Engine Image object outputted by the map_DFO_event function\n",
    "        roiGEO : the region of interest as an Earth Engine Geometry object\n",
    "\n",
    "    Returns:\n",
    "    -an image of people in the mapped flood from WorldPop data\n",
    "\n",
    "    \"\"\"\n",
    "    import ee\n",
    "    import geemap\n",
    "    ee.Initialize()\n",
    "    # ee.Authenticate()\n",
    "    roi_geo = flood_img.geometry()\n",
    "\n",
    "    # Import the LandScan image collection & permannt water mask\n",
    "    perm_water = ee.Image(\"JRC/GSW1_0/GlobalSurfaceWater\").select(\"transition\").eq(1).unmask()\n",
    "    # print('Band names:', flood_img.bandNames().getInfo())\n",
    "    def maskImages(img):\n",
    "        non_flood = img.select(\"flooded\")\n",
    "        water_mask = non_flood.multiply(perm_water.neq(1))\n",
    "        return img.select(\"flooded\").mask(water_mask)\n",
    "\n",
    "    def durationImages(img):\n",
    "            non_flood = img.select(\"flooded\")\n",
    "            water_mask = non_flood.multiply(perm_water.neq(1))\n",
    "            return img.select(\"duration\").mask(water_mask)\n",
    "\n",
    "    # Extract the final flood extent image data as its own variable for analysis\n",
    "    # flood_extent = maskImages(ee.Image(flood_img.select(\"flooded\")))\n",
    "    # flood_duration = durationImages(ee.Image(flood_img.select(\"flood_duration\")))\n",
    "    flood_extent = maskImages(ee.Image(flood_img))\n",
    "    flood_duration = durationImages(ee.Image(flood_img))\n",
    "\n",
    "\n",
    "    # # get pop from projects/global-flood-db/landscan\n",
    "    # # Get event year, match with the population year and clip to study are\n",
    "    # pop_all = ee.ImageCollection(\"projects/global-flood-db/landscan\")\n",
    "    # event_year = ee.Date(flood_img.get('began')).get('year')\n",
    "    # pop_img = ee.Image(pop_all.filterMetadata('year', 'equals', event_year)\\\n",
    "    #                 .first()).clip(roi_geo)\n",
    "    # pop_img = pop_img.updateMask(pop_img.gte(0)) # mask out bad data with negative values\n",
    "\n",
    "    # get pop from JRC/GHSL/P2016/POP_GPW_GLOBE_V1\n",
    "    pop_all = ee.ImageCollection(\"JRC/GHSL/P2016/POP_GPW_GLOBE_V1\")\n",
    "    # Get event year to match with the population year\n",
    "    # pop_img = ee.Image(pop_all.filterMetadata('system:index', 'equals', '2000')\\\n",
    "    #                 .first()).clip(roi_geo)\n",
    "    pop_img = ee.Image(pop_all.filterMetadata('system:index', 'equals', '2015')\\\n",
    "                    .first()).clip(roi_geo)\n",
    "\n",
    "\n",
    "    # Mask the world population dataset using the flood extent layer\n",
    "    pop_masked = pop_img.updateMask(flood_extent)\n",
    "\n",
    "    pop_duration = pop_masked.multiply(flood_duration)\n",
    "    return flood_extent, flood_duration, pop_img, pop_masked, pop_duration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913\n"
     ]
    }
   ],
   "source": [
    "# identify the administrative region covered by each flood event\n",
    "import ee\n",
    "ee.Initialize()\n",
    "\n",
    "import time, csv\n",
    "# from flood_stats import pop_utils\n",
    "\n",
    "# Image Collection of flood maps, each needs layer called \"flooded\" that\n",
    "# is 1 = flooded, 0 = not flooded\n",
    "gfd = ee.ImageCollection('projects/global-flood-db/gfd_v3').filterMetadata('id','greater_than',1).filterMetadata('id','less_than',5000)\n",
    "\n",
    "# 1-2500; 2500-3000 3500-5000\n",
    "# gfd = ee.ImageCollection('projects/global-flood-db/gfd_v3').filterMetadata('id','greater_than',4710)\n",
    "\n",
    "# greater_than\n",
    "# 1500\n",
    "\n",
    "\n",
    "# Create Error Log file\n",
    "log_file = \"../error_logs/event_stats/pop_error_log_{0}.csv\".format(time.strftime(\"%d_%m_%Y\"))\n",
    "with open(log_file,\"w\", newline='') as out_file:\n",
    "    wr = csv.writer(out_file)\n",
    "    wr.writerow([\"error_type\", \"dfo_id\", \"error_message\"])\n",
    "\n",
    "# Create list of events from input fusion table\n",
    "event_ids = ee.List(gfd.aggregate_array('id')).sort()\n",
    "id_list = event_ids.getInfo()\n",
    "id_list = [int(i) for i in id_list]\n",
    "print(len(id_list))\n",
    "# print(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "GPM = ee.ImageCollection('projects/climate-engine-pro/assets/ce-gpm-imerg-daily')  # Use 'precipitationCal' or the appropriate band\n",
    "ASTER_GDEM = ee.Image('projects/sat-io/open-datasets/ASTER/GDEM')\n",
    "\n",
    "slope = ee.Terrain.slope(ASTER_GDEM)\n",
    "\n",
    "GISD = ee.Image('projects/sat-io/open-datasets/GISD30_1985_2020')\n",
    "# gisd_dict = {1983: \"GISD30_1985_2020\"}\n",
    "GCN250_wet = ee.Image(\"users/jaafarhadi/GCN250/GCN250Wet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea210e707fcb449b9c5cbfccb06e4f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[0, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=SearchDataGUI(childr…"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slope and dem\n",
    "def dem_slope(flood_image):\n",
    "    flood_event_info = flood_image.getInfo()\n",
    "    roi_geo = flood_image.geometry()\n",
    "    event_slope = slope.clip(roi_geo)\n",
    "    event_dem = ASTER_GDEM.clip(roi_geo)\n",
    "    \n",
    "    return event_dem, event_slope\n",
    "\n",
    "first_image = gfd.first()\n",
    "first_image = ee.Image(gfd.filterMetadata('id', 'equals', 4683).first())\n",
    "\n",
    "roi_geo = first_image.geometry()\n",
    "event_dem, event_slope = dem_slope(first_image)\n",
    "\n",
    "prec_palette = [\"#ffffcc\", \"#c7e9b4\", \"#7fcdbb\", \"#41b6c4\", \"#1d91c0\", \"#225ea8\", \"#0c2c84\"];\n",
    "visParams = {\"min\": 0, \"max\": 2, \"palette\": prec_palette}\n",
    "\n",
    "Map = geemap.Map()\n",
    "Map.addLayer(event_slope, visParams, 'dem')\n",
    "\n",
    "Map.centerObject(roi_geo)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GISD & GCN\n",
    "def event_GISD_GCN(flood_image):\n",
    "    flood_event_info = flood_image.getInfo()\n",
    "    roi_geo = flood_image.geometry()\n",
    "    event_gisd = GISD.clip(roi_geo)\n",
    "    event_gcn = GCN250_wet.clip(roi_geo)\n",
    "\n",
    "    return event_gisd, event_gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the percipitation\n",
    "\n",
    "def max_cumu_prec13730(flood_image):\n",
    "    flood_event_info = flood_image.getInfo()\n",
    "    roi_geo = flood_image.geometry()\n",
    "    # .advance(-3, 'day')\n",
    "    gpm = GPM.filterDate(ee.Date(flood_event_info['properties']['began']).advance(-3, 'day'), \n",
    "                         ee.Date(flood_event_info['properties']['ended'])).filterBounds(roi_geo).select('precipitationCal')\n",
    "\n",
    "    # Define a function to calculate the rolling sum over a specified number of days\n",
    "    def max_rolling_sum(window_size):\n",
    "\n",
    "        \n",
    "        image_collection = gpm\n",
    "\n",
    "        def sum_over_window(n):\n",
    "            # Calculate the sum over the window for each position\n",
    "            start = ee.Date(image_collection.first().get('system:time_start')).advance(n, 'day')\n",
    "            end = start.advance(window_size, 'day')\n",
    "            sum_window = image_collection.filterDate(start, end).sum().set('system:time_start', start.millis())\n",
    "            return sum_window\n",
    "        \n",
    "        # Generate a list of numbers to create the rolling window\n",
    "        len_number = image_collection.size().subtract(window_size)\n",
    "        # numbers =\n",
    "        if len_number.getInfo() < 0:\n",
    "            return False, False\n",
    "        else:\n",
    "            summed_collection = ee.ImageCollection(ee.List.sequence(0, len_number).map(sum_over_window))\n",
    "\n",
    "            return summed_collection.reduce(ee.Reducer.max()), True\n",
    "    \n",
    "    intervals = [1, 3, 7, 30]\n",
    "    max_precipitation_maps = {}\n",
    "    for inter in intervals:\n",
    "        inter_max_preci_maps, tag = max_rolling_sum(inter)\n",
    "        if tag:\n",
    "            max_precipitation_maps[f'{inter}-day'] = inter_max_preci_maps\n",
    "        else:\n",
    "            break\n",
    "    # intervals = [1]\n",
    "    # max_precipitation_maps = {f'{interval}-day': max_rolling_sum(interval) for interval in intervals}\n",
    "    # max_pre_map_1 = max_rolling_sum(1)\n",
    "    # max_pre_map_3 = max_rolling_sum(3)\n",
    "    # max_pre_map_7 = max_rolling_sum(7)\n",
    "    # max_pre_map_30 = max_rolling_sum(30)\n",
    "    # return max_pre_map_1, max_pre_map_3, max_pre_map_7, max_pre_map_30\n",
    "\n",
    "    return max_precipitation_maps\n",
    "\n",
    "first_image = gfd.first()\n",
    "first_image = ee.Image(gfd.filterMetadata('id', 'equals', 4683).first())\n",
    "\n",
    "roi_geo = first_image.geometry()\n",
    "max_pre_map_1, max_pre_map_3, max_pre_map_7, max_pre_map_30 = max_cumu_prec13730(first_image)\n",
    "\n",
    "# prec_palette = [\"#ffffcc\", \"#c7e9b4\", \"#7fcdbb\", \"#41b6c4\", \"#1d91c0\", \"#225ea8\", \"#0c2c84\"];\n",
    "# visParams = {\"min\": 0, \"max\": 200, \"palette\": prec_palette}\n",
    "\n",
    "Map = geemap.Map()\n",
    "# Map.addLayer(max_precipitation_maps['1-day'], visParams, 'Max 1 Day Precipitation')\n",
    "\n",
    "# style = {\n",
    "#   \"color\": '000000',  \n",
    "#   \"fillColor\": '00000000'  \n",
    "# }\n",
    "\n",
    "# Map.addLayer(roi_geo, style, 'ROI')\n",
    "# Map.addLayer(first_image, {\"colormap\": \"jet\", \"bands\": ['duration']}, 'flood')\n",
    "# Map.centerObject(roi_geo)\n",
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dfo_centroid_y': -31.268059, 'dfo_main_cause': 'Monsoonal rain', 'gfd_country_name': \"['AUSTRALIA']\", 'dfo_centroid_x': 143.6978, 'glide_index': 'NA', 'slope_threshold': 5, 'dfo_severity': 2, 'system:footprint': {'type': 'LinearRing', 'coordinates': [[139.6005812730815, -17.518267010104264], [138.4040674236775, -17.51707155596811], [137.20519449393421, -17.518262275331107], [137.20471106885168, -37.68095660034486], [139.99941925183816, -37.680961429261664], [141.9936089883675, -37.680961430234674], [143.98779872401195, -37.680961424329006], [145.58315055189232, -37.68096143983046], [147.97617824298896, -37.680961381848334], [149.97321059715983, -37.68095662726775], [149.97272709473495, -17.518262280872825], [148.77385413322452, -17.51707158835981], [147.57734028086537, -17.518267026312603], [146.38082649061207, -17.517071608501123], [145.18431256933783, -17.518267014811364], [143.98779872401195, -17.51707157652277], [142.39244698359286, -17.51707158759303], [140.79709518683185, -17.517071570794638], [139.6005812730815, -17.518267010104264]]}, 'threshold_b1b2': 0.711, 'otsu_sample_res': 231.66, 'dfo_displaced': 200, 'id': 1586, 'cc': 'AUS', 'began': '2000-02-18', 'dfo_validation_type': 'News', 'composite_type': '3Day', 'dfo_country': 'Australia', 'countries': 'Australia', 'dfo_other_country': 'NA', 'dfo_dead': 1, 'gfd_country_code': \"['AS']\", 'ended': '2000-03-01', 'threshold_type': 'otsu', 'threshold_b7': 1815.18, 'system:asset_size': 8987006, 'system:index': 'DFO_1586_From_20000218_to_20000301'}\n",
      "dict_keys(['dfo_centroid_y', 'dfo_main_cause', 'gfd_country_name', 'dfo_centroid_x', 'glide_index', 'slope_threshold', 'dfo_severity', 'system:footprint', 'threshold_b1b2', 'otsu_sample_res', 'dfo_displaced', 'id', 'cc', 'began', 'dfo_validation_type', 'composite_type', 'dfo_country', 'countries', 'dfo_other_country', 'dfo_dead', 'gfd_country_code', 'ended', 'threshold_type', 'threshold_b7', 'system:asset_size', 'system:index'])\n",
      "AUS\n"
     ]
    }
   ],
   "source": [
    "first_image = gfd.first()\n",
    "\n",
    "# Retrieve information about the first image as a dictionary.\n",
    "first_image_info = first_image.getInfo()\n",
    "\n",
    "# Now you can print or inspect 'first_image_info' to see all properties.\n",
    "print(first_image_info['properties'])\n",
    "\n",
    "# If you want to see all property names (keys) of the first image:\n",
    "property_names = first_image_info['properties'].keys()\n",
    "print(property_names)\n",
    "\n",
    "print(first_image_info['properties']['cc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对每个洪涝灾害，识别覆盖的行政单元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913\n",
      "DFO 1614 is in VNM, THA, LAO, KHM\n",
      "found 80 regions covered by the flood event\n",
      "calculated results for DFO 1614...\n",
      "Exporting FeatureCollection to CSV..._1614\n",
      "DFO 1627 is in RUS, CHN, KOR, PRK\n",
      "found 34 regions covered by the flood event\n",
      "calculated results for DFO 1627...\n",
      "Exporting FeatureCollection to CSV..._1627\n",
      "DFO 1631 is in CHN, HKG\n",
      "found 13 regions covered by the flood event\n",
      "calculated results for DFO 1631...\n",
      "Exporting FeatureCollection to CSV..._1631\n",
      "DFO 1641 is in CHN, IND, NPL, BGD, BTN\n",
      "found 56 regions covered by the flood event\n",
      "calculated results for DFO 1641...\n",
      "Exporting FeatureCollection to CSV..._1641\n",
      "DFO 1725 is in RUS, CHN, MNG, KAZ\n",
      "found 56 regions covered by the flood event\n",
      "calculated results for DFO 1725...\n",
      "Exporting FeatureCollection to CSV..._1725\n",
      "DFO 1747 is in IND, BGD\n",
      "found 17 regions covered by the flood event\n",
      "calculated results for DFO 1747...\n",
      "Exporting FeatureCollection to CSV..._1747\n",
      "DFO 1772 is in SDN, ETH, EGY\n",
      "found 27 regions covered by the flood event\n",
      "calculated results for DFO 1772...\n",
      "Exporting FeatureCollection to CSV..._1772\n",
      "DFO 1778 is in SDN, TCD, NGA, CAF, CMR\n",
      "found 63 regions covered by the flood event\n",
      "calculated results for DFO 1778...\n",
      "Exporting FeatureCollection to CSV..._1778\n",
      "DFO 1781 is in VNM, THA, LAO, KHM\n",
      "found 80 regions covered by the flood event\n",
      "calculated results for DFO 1781...\n",
      "Exporting FeatureCollection to CSV..._1781\n",
      "DFO 1789 is in CHN, IND, NPL, BGD\n",
      "found 27 regions covered by the flood event\n",
      "calculated results for DFO 1789...\n",
      "Exporting FeatureCollection to CSV..._1789\n",
      "DFO 1791 is in CHN, IND, NPL, BGD\n",
      "found 27 regions covered by the flood event\n",
      "calculated results for DFO 1791...\n",
      "Exporting FeatureCollection to CSV..._1791\n",
      "DFO 1793 is in MLI, MRT, GIN, BFA\n",
      "found 33 regions covered by the flood event\n",
      "calculated results for DFO 1793...\n",
      "Exporting FeatureCollection to CSV..._1793\n",
      "DFO 1810 is in ARG\n",
      "found 1 regions covered by the flood event\n",
      "calculated results for DFO 1810...\n",
      "Exporting FeatureCollection to CSV..._1810\n",
      "DFO 1818 is in MEX, CUB, GTM, NIC, HND, BLZ\n",
      "found 40 regions covered by the flood event\n",
      "calculated results for DFO 1818...\n",
      "Exporting FeatureCollection to CSV..._1818\n",
      "DFO 1820 is in ETH\n",
      "found 3 regions covered by the flood event\n",
      "calculated results for DFO 1820...\n",
      "Exporting FeatureCollection to CSV..._1820\n",
      "DFO 1829 is in USA\n",
      "found 28 regions covered by the flood event\n",
      "calculated results for DFO 1829...\n",
      "Exporting FeatureCollection to CSV..._1829\n",
      "DFO 1840 is in USA\n",
      "found 28 regions covered by the flood event\n",
      "calculated results for DFO 1840...\n",
      "Exporting FeatureCollection to CSV..._1840\n",
      "DFO 1885 is in BRA\n",
      "found 10 regions covered by the flood event\n",
      "calculated results for DFO 1885...\n",
      "Exporting FeatureCollection to CSV..._1885\n",
      "DFO 1907 is in ETH, DJI\n",
      "found 15 regions covered by the flood event\n",
      "calculated results for DFO 1907...\n",
      "Exporting FeatureCollection to CSV..._1907\n",
      "DFO 1908 is in BGD\n",
      "found 7 regions covered by the flood event\n",
      "calculated results for DFO 1908...\n",
      "Exporting FeatureCollection to CSV..._1908\n",
      "DFO 1910 is in RUS, KAZ\n",
      "found 18 regions covered by the flood event\n",
      "calculated results for DFO 1910...\n",
      "Exporting FeatureCollection to CSV..._1910\n",
      "DFO 1917 is in SDN, ETH, KEN, COD, MOZ, SOM, UGA, TZA, MWI, ZMB, BDI, RWA\n",
      "found 195 regions covered by the flood event\n",
      "calculated results for DFO 1917...\n",
      "Exporting FeatureCollection to CSV..._1917\n",
      "DFO 1919 is in CAN, USA\n",
      "found 39 regions covered by the flood event\n",
      "calculated results for DFO 1919...\n",
      "Exporting FeatureCollection to CSV..._1919\n",
      "DFO 1921 is in RUS, KAZ\n",
      "found 18 regions covered by the flood event\n",
      "calculated results for DFO 1921...\n",
      "Exporting FeatureCollection to CSV..._1921\n",
      "DFO 1925 is in BRA, ARG, BOL, PRY, URY\n",
      "found 26 regions covered by the flood event\n",
      "calculated results for DFO 1925...\n",
      "Exporting FeatureCollection to CSV..._1925\n",
      "DFO 1931 is in RUS\n",
      "found 4 regions covered by the flood event\n",
      "calculated results for DFO 1931...\n",
      "Exporting FeatureCollection to CSV..._1931\n",
      "DFO 1938 is in TUR, EGY, SYR, ISR, CYP, LBN\n",
      "found 29 regions covered by the flood event\n",
      "calculated results for DFO 1938...\n",
      "Exporting FeatureCollection to CSV..._1938\n",
      "DFO 1939 is in BRA, ARG, URY\n",
      "found 5 regions covered by the flood event\n",
      "calculated results for DFO 1939...\n",
      "Exporting FeatureCollection to CSV..._1939\n",
      "DFO 1943 is in CAN, USA\n",
      "found 17 regions covered by the flood event\n",
      "calculated results for DFO 1943...\n",
      "Exporting FeatureCollection to CSV..._1943\n",
      "DFO 1951 is in CUB\n",
      "found 1 regions covered by the flood event\n",
      "calculated results for DFO 1951...\n",
      "Exporting FeatureCollection to CSV..._1951\n",
      "DFO 1962 is in RUS, IRN, TUR, AZE, GEO, ARM\n",
      "found 51 regions covered by the flood event\n",
      "calculated results for DFO 1962...\n",
      "Exporting FeatureCollection to CSV..._1962\n",
      "DFO 1971 is in CHN\n",
      "found 25 regions covered by the flood event\n",
      "calculated results for DFO 1971...\n",
      "Exporting FeatureCollection to CSV..._1971\n",
      "DFO 1972 is in USA, MEX\n",
      "found 13 regions covered by the flood event\n",
      "calculated results for DFO 1972...\n",
      "Exporting FeatureCollection to CSV..._1972\n",
      "DFO 1974 is in CHN, IND, MMR, NPL, BGD, BTN\n",
      "found 63 regions covered by the flood event\n",
      "calculated results for DFO 1974...\n",
      "Exporting FeatureCollection to CSV..._1974\n",
      "DFO 1977 is in COL, VEN\n",
      "found 15 regions covered by the flood event\n",
      "calculated results for DFO 1977...\n",
      "Exporting FeatureCollection to CSV..._1977\n",
      "DFO 1979 is in CAN, USA\n",
      "found 19 regions covered by the flood event\n",
      "calculated results for DFO 1979...\n",
      "Exporting FeatureCollection to CSV..._1979\n",
      "DFO 1980 is in CHN, IND, NPL\n",
      "found 23 regions covered by the flood event\n",
      "calculated results for DFO 1980...\n",
      "Exporting FeatureCollection to CSV..._1980\n",
      "DFO 1981 is in PHL\n",
      "found 17 regions covered by the flood event\n",
      "calculated results for DFO 1981...\n",
      "Exporting FeatureCollection to CSV..._1981\n",
      "DFO 1985 is in NZL\n",
      "found 11 regions covered by the flood event\n",
      "calculated results for DFO 1985...\n",
      "Exporting FeatureCollection to CSV..._1985\n",
      "DFO 1991 is in VNM, THA, LAO, KHM\n",
      "found 80 regions covered by the flood event\n",
      "calculated results for DFO 1991...\n",
      "Exporting FeatureCollection to CSV..._1991\n",
      "DFO 1995 is in TUR, ROU, BGR, SRB\n",
      "found 11 regions covered by the flood event\n",
      "calculated results for DFO 1995...\n",
      "Exporting FeatureCollection to CSV..._1995\n",
      "DFO 1996 is in BRA, COL, VEN, GUY\n",
      "found 39 regions covered by the flood event\n",
      "calculated results for DFO 1996...\n",
      "Exporting FeatureCollection to CSV..._1996\n",
      "DFO 1997 is in RUS, CHN, PRK\n",
      "found 10 regions covered by the flood event\n",
      "calculated results for DFO 1997...\n",
      "Exporting FeatureCollection to CSV..._1997\n",
      "DFO 1998 is in PHL\n",
      "found 17 regions covered by the flood event\n",
      "calculated results for DFO 1998...\n",
      "Exporting FeatureCollection to CSV..._1998\n",
      "DFO 1999 is in CHN, IND, NPL, BGD\n",
      "found 27 regions covered by the flood event\n",
      "calculated results for DFO 1999...\n",
      "Exporting FeatureCollection to CSV..._1999\n",
      "DFO 2007 is in CAN, USA\n",
      "found 2 regions covered by the flood event\n",
      "calculated results for DFO 2007...\n",
      "Exporting FeatureCollection to CSV..._2007\n",
      "DFO 2009 is in ZAF\n",
      "found 2 regions covered by the flood event\n",
      "calculated results for DFO 2009...\n",
      "Exporting FeatureCollection to CSV..._2009\n",
      "DFO 2019 is in CHN\n",
      "found 3 regions covered by the flood event\n",
      "calculated results for DFO 2019...\n",
      "Exporting FeatureCollection to CSV..._2019\n",
      "DFO 2023 is in CHN\n",
      "found 21 regions covered by the flood event\n",
      "calculated results for DFO 2023...\n",
      "Exporting FeatureCollection to CSV..._2023\n",
      "DFO 2024 is in ITA, POL, DEU, FRA, SRB, HRV, SVK, HUN, CZE, AUT, CHE, DNK, SVN, NLD, LUX\n",
      "found 55 regions covered by the flood event\n",
      "calculated results for DFO 2024...\n",
      "Exporting FeatureCollection to CSV..._2024\n",
      "DFO 2029 is in IRN, TKM\n",
      "found 6 regions covered by the flood event\n",
      "calculated results for DFO 2029...\n",
      "Exporting FeatureCollection to CSV..._2029\n",
      "DFO 2035 is in CHN, VNM\n",
      "found 11 regions covered by the flood event\n",
      "calculated results for DFO 2035...\n",
      "Exporting FeatureCollection to CSV..._2035\n",
      "DFO 2039 is in CHN, MMR, VNM, THA, LAO, KHM\n",
      "found 97 regions covered by the flood event\n",
      "calculated results for DFO 2039...\n",
      "Exporting FeatureCollection to CSV..._2039\n",
      "DFO 2041 is in CHN, IND, MMR\n",
      "found 11 regions covered by the flood event\n",
      "calculated results for DFO 2041...\n",
      "Exporting FeatureCollection to CSV..._2041\n",
      "DFO 2042 is in CHL, ARG\n",
      "found 12 regions covered by the flood event\n",
      "calculated results for DFO 2042...\n",
      "Exporting FeatureCollection to CSV..._2042\n",
      "DFO 2045 is in KOR, PRK\n",
      "found 12 regions covered by the flood event\n",
      "calculated results for DFO 2045...\n",
      "Exporting FeatureCollection to CSV..._2045\n",
      "DFO 2046 is in RUS, CHN\n",
      "found 6 regions covered by the flood event\n",
      "calculated results for DFO 2046...\n",
      "Exporting FeatureCollection to CSV..._2046\n",
      "DFO 2049 is in IND\n",
      "found 16 regions covered by the flood event\n",
      "calculated results for DFO 2049...\n",
      "Exporting FeatureCollection to CSV..._2049\n",
      "DFO 2052 is in ESP, FRA, CHE\n",
      "found 33 regions covered by the flood event\n",
      "calculated results for DFO 2052...\n",
      "Exporting FeatureCollection to CSV..._2052\n",
      "DFO 2056 is in USA, MEX\n",
      "found 8 regions covered by the flood event\n",
      "calculated results for DFO 2056...\n",
      "Exporting FeatureCollection to CSV..._2056\n",
      "DFO 2059 is in VNM, THA, LAO, KHM\n",
      "found 49 regions covered by the flood event\n",
      "calculated results for DFO 2059...\n",
      "Exporting FeatureCollection to CSV..._2059\n",
      "DFO 2060 is in TUR, ITA, GRC, BGR, SRB, HRV, ALB, MKD, BIH, SVN\n",
      "found 40 regions covered by the flood event\n",
      "calculated results for DFO 2060...\n",
      "Exporting FeatureCollection to CSV..._2060\n",
      "DFO 2061 is in MMR, VNM, MYS, THA, KHM, SGP\n",
      "found 105 regions covered by the flood event\n",
      "calculated results for DFO 2061...\n",
      "Exporting FeatureCollection to CSV..._2061\n",
      "DFO 2063 is in USA\n",
      "found 5 regions covered by the flood event\n",
      "calculated results for DFO 2063...\n",
      "Exporting FeatureCollection to CSV..._2063\n",
      "DFO 2064 is in USA, CUB, JAM\n",
      "found 9 regions covered by the flood event\n",
      "calculated results for DFO 2064...\n",
      "Exporting FeatureCollection to CSV..._2064\n",
      "DFO 2066 is in USA\n",
      "found 9 regions covered by the flood event\n",
      "calculated results for DFO 2066...\n",
      "Exporting FeatureCollection to CSV..._2066\n",
      "DFO 2070 is in BRA, ARG, BOL, PRY, URY\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\connectionpool.py:777\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 777\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m, SocketTimeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\connectionpool.py:1046\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._prepare_proxy\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1040\u001b[0m conn\u001b[38;5;241m.\u001b[39mset_tunnel(\n\u001b[0;32m   1041\u001b[0m     scheme\u001b[38;5;241m=\u001b[39mtunnel_scheme,\n\u001b[0;32m   1042\u001b[0m     host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host,\n\u001b[0;32m   1043\u001b[0m     port\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport,\n\u001b[0;32m   1044\u001b[0m     headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy_headers,\n\u001b[0;32m   1045\u001b[0m )\n\u001b[1;32m-> 1046\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\connection.py:642\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    635\u001b[0m         (\n\u001b[0;32m    636\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystem time is way off (before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRECENT_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). This will probably \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    639\u001b[0m         SystemTimeWarning,\n\u001b[0;32m    640\u001b[0m     )\n\u001b[1;32m--> 642\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\connection.py:783\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    781\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[1;32m--> 783\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\util\\ssl_.py:471\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\util\\ssl_.py:515\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m--> 515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\ssl.py:1040\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1040\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\ssl.py:1309\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1308\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1309\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] 远程主机强迫关闭了一个现有的连接。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\connectionpool.py:845\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    843\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 845\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    848\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\util\\retry.py:470\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\util\\util.py:38\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\connectionpool.py:777\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 777\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m, SocketTimeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\connectionpool.py:1046\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._prepare_proxy\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1040\u001b[0m conn\u001b[38;5;241m.\u001b[39mset_tunnel(\n\u001b[0;32m   1041\u001b[0m     scheme\u001b[38;5;241m=\u001b[39mtunnel_scheme,\n\u001b[0;32m   1042\u001b[0m     host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host,\n\u001b[0;32m   1043\u001b[0m     port\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport,\n\u001b[0;32m   1044\u001b[0m     headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy_headers,\n\u001b[0;32m   1045\u001b[0m )\n\u001b[1;32m-> 1046\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\connection.py:642\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    635\u001b[0m         (\n\u001b[0;32m    636\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystem time is way off (before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRECENT_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). This will probably \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    639\u001b[0m         SystemTimeWarning,\n\u001b[0;32m    640\u001b[0m     )\n\u001b[1;32m--> 642\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\connection.py:783\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    781\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[1;32m--> 783\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\util\\ssl_.py:471\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\urllib3\\util\\ssl_.py:515\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m--> 515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\ssl.py:1040\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1040\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\ssl.py:1309\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1308\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1309\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 109\u001b[0m\n\u001b[0;32m    106\u001b[0m gisd_scale \u001b[38;5;241m=\u001b[39m gisd\u001b[38;5;241m.\u001b[39mprojection()\u001b[38;5;241m.\u001b[39mnominalScale()\n\u001b[0;32m    107\u001b[0m gcn_scale \u001b[38;5;241m=\u001b[39m gcn\u001b[38;5;241m.\u001b[39mprojection()\u001b[38;5;241m.\u001b[39mnominalScale()\n\u001b[1;32m--> 109\u001b[0m flood_extent, flood_duration, pop_img, pop_masked, pop_duration \u001b[38;5;241m=\u001b[39m \u001b[43mget_flood_pop_pixel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflood_event\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Filter the regions covered by the flood event\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# gdf_coun = gdf[gdf['code'].isin(country_codes_list)]\u001b[39;00m\n\u001b[0;32m    113\u001b[0m gdf_coun \u001b[38;5;241m=\u001b[39m gdf\u001b[38;5;241m.\u001b[39mfilter(ee\u001b[38;5;241m.\u001b[39mFilter\u001b[38;5;241m.\u001b[39minList(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m, ee\u001b[38;5;241m.\u001b[39mList(country_codes_list)))\n",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m, in \u001b[0;36mget_flood_pop_pixel\u001b[1;34m(flood_img)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mee\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeemap\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mee\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# ee.Authenticate()\u001b[39;00m\n\u001b[0;32m     28\u001b[0m roi_geo \u001b[38;5;241m=\u001b[39m flood_img\u001b[38;5;241m.\u001b[39mgeometry()\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\ee\\__init__.py:136\u001b[0m, in \u001b[0;36mInitialize\u001b[1;34m(credentials, opt_url, cloud_api_key, http_transport, project)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m credentials \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpersistent\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    134\u001b[0m   credentials \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget_persistent_credentials()\n\u001b[1;32m--> 136\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_base_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt_url\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mopt_url\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtile_base_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloud_api_base_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloud_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcloud_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp_transport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_transport\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Initialize the dynamically loaded functions on the objects that want them.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m ApiFunction\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\ee\\data.py:215\u001b[0m, in \u001b[0;36minitialize\u001b[1;34m(credentials, api_base_url, tile_base_url, cloud_api_base_url, cloud_api_key, project, http_transport)\u001b[0m\n\u001b[0;32m    211\u001b[0m   _cloud_api_client_version \u001b[38;5;241m=\u001b[39m version\n\u001b[0;32m    213\u001b[0m _http_transport \u001b[38;5;241m=\u001b[39m http_transport\n\u001b[1;32m--> 215\u001b[0m \u001b[43m_install_cloud_api_resource\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m   _cloud_api_user_project \u001b[38;5;241m=\u001b[39m project\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\ee\\data.py:276\u001b[0m, in \u001b[0;36m_install_cloud_api_resource\u001b[1;34m()\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _cloud_api_resource, _cloud_api_resource_raw\n\u001b[0;32m    275\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (_deadline_ms \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000.0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m _cloud_api_resource \u001b[38;5;241m=\u001b[39m \u001b[43m_cloud_api_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_cloud_resource\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_cloud_api_base_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_cloud_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders_supplier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_make_request_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_inspector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_handle_profiling_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp_transport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_http_transport\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m _cloud_api_resource_raw \u001b[38;5;241m=\u001b[39m _cloud_api_utils\u001b[38;5;241m.\u001b[39mbuild_cloud_resource(\n\u001b[0;32m    286\u001b[0m     _cloud_api_base_url,\n\u001b[0;32m    287\u001b[0m     credentials\u001b[38;5;241m=\u001b[39m_credentials,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    292\u001b[0m     http_transport\u001b[38;5;241m=\u001b[39m_http_transport,\n\u001b[0;32m    293\u001b[0m     raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\ee\\_cloud_api_utils.py:204\u001b[0m, in \u001b[0;36mbuild_cloud_resource\u001b[1;34m(api_base_url, api_key, credentials, timeout, headers_supplier, response_inspector, http_transport, raw)\u001b[0m\n\u001b[0;32m    199\u001b[0m resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;66;03m# google-api-python-client made static_discovery the default in version 2,\u001b[39;00m\n\u001b[0;32m    202\u001b[0m   \u001b[38;5;66;03m# but it's not backward-compatible. There's no reliable way to check the\u001b[39;00m\n\u001b[0;32m    203\u001b[0m   \u001b[38;5;66;03m# package version, either.\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m   resource \u001b[38;5;241m=\u001b[39m \u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatic_discovery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Handle fallback case outside except block, for cleaner stack traces.\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\ee\\_cloud_api_utils.py:188\u001b[0m, in \u001b[0;36mbuild_cloud_resource.<locals>.build\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 188\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdiscovery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mearthengine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m      \u001b[49m\u001b[43mVERSION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdiscoveryServiceUrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscovery_service_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeveloperKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m      \u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_transport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m      \u001b[49m\u001b[43mrequestBuilder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_builder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malt_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcache_discovery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\googleapiclient\\discovery.py:287\u001b[0m, in \u001b[0;36mbuild\u001b[1;34m(serviceName, version, http, discoveryServiceUrl, developerKey, model, requestBuilder, credentials, cache_discovery, cache, client_options, adc_cert_path, adc_key_path, num_retries, static_discovery, always_use_jwt_access)\u001b[0m\n\u001b[0;32m    284\u001b[0m requested_url \u001b[38;5;241m=\u001b[39m uritemplate\u001b[38;5;241m.\u001b[39mexpand(discovery_url, params)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 287\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[43m_retrieve_discovery_doc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequested_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiscovery_http\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_discovery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserviceName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeveloperKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatic_discovery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_discovery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m     service \u001b[38;5;241m=\u001b[39m build_from_document(\n\u001b[0;32m    299\u001b[0m         content,\n\u001b[0;32m    300\u001b[0m         base\u001b[38;5;241m=\u001b[39mdiscovery_url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    309\u001b[0m         always_use_jwt_access\u001b[38;5;241m=\u001b[39malways_use_jwt_access,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# exit if a service was created\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\googleapiclient\\discovery.py:422\u001b[0m, in \u001b[0;36m_retrieve_discovery_doc\u001b[1;34m(url, http, cache_discovery, serviceName, version, cache, developerKey, num_retries, static_discovery)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# Execute this request with retries build into HttpRequest\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# Note that it will already raise an error if we don't get a 2xx response\u001b[39;00m\n\u001b[0;32m    421\u001b[0m req \u001b[38;5;241m=\u001b[39m HttpRequest(http, HttpRequest\u001b[38;5;241m.\u001b[39mnull_postproc, actual_url)\n\u001b[1;32m--> 422\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m \u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    425\u001b[0m     content \u001b[38;5;241m=\u001b[39m content\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\googleapiclient\\http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody))\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[1;32m--> 923\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_callbacks:\n\u001b[0;32m    936\u001b[0m     callback(resp)\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\googleapiclient\\http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[1;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     resp, content \u001b[38;5;241m=\u001b[39m \u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _ssl_SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_error:\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\google_auth_httplib2.py:218\u001b[0m, in \u001b[0;36mAuthorizedHttp.request\u001b[1;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m     body_stream_position \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# Make the request.\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m response, content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mredirections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredirections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    234\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh_status_codes\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m _credential_refresh_attempt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_refresh_attempts\n\u001b[0;32m    236\u001b[0m ):\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\ee\\_cloud_api_utils.py:79\u001b[0m, in \u001b[0;36m_Http.request\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m     78\u001b[0m   session\u001b[38;5;241m.\u001b[39mmax_redirects \u001b[38;5;241m=\u001b[39m redirections\n\u001b[1;32m---> 79\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m   headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(response\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[0;32m     82\u001b[0m   headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\satellite_flooding\\lib\\site-packages\\requests\\adapters.py:501\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "# Load the shapefile\n",
    "\n",
    "gdf = ee.FeatureCollection(\"projects/ee-dcy0910/assets/GSAP2\")\n",
    "\n",
    "gfd = ee.ImageCollection('projects/global-flood-db/gfd_v3').filterMetadata('id','greater_than',1)\n",
    "\n",
    "# 2070\n",
    "# .filterDate(ee.DateRange('2000-06-01','2019-01-01'))\n",
    "# 1-2500; 2500-3000 3500-5000\n",
    "# gfd = ee.ImageCollection('projects/global-flood-db/gfd_v3').filterMetadata('id','greater_than',4710)\n",
    "\n",
    "# Create list of events from input fusion table\n",
    "event_ids = ee.List(gfd.aggregate_array('id')).sort()\n",
    "id_list = event_ids.getInfo()\n",
    "id_list = [int(i) for i in id_list]\n",
    "print(len(id_list))\n",
    "# # Convert GeoSeries to list of shapely geometries\n",
    "# gdf['geometry'] = gdf['geometry'].apply(lambda x: shape(x))\n",
    "# id_list = [2753]\n",
    "all_regions_stats_ge = []  # List to store regions_stats of each event\n",
    "all_regions_stats = []\n",
    "# id_list = [4673]\n",
    "# 4683\n",
    "for event_id in id_list:\n",
    "    # Get event date range, they can be passed as Strings\n",
    "    flood_event = ee.Image(gfd.filterMetadata('id', 'equals', event_id).first())\n",
    "    flood_event_info = flood_event.getInfo()\n",
    "    if ee.Date(flood_event_info['properties']['began']).millis().gte(ee.Date('2000-06-01').millis()).getInfo():\n",
    "            \n",
    "\n",
    "        # print(flood_event_info['properties']['gfd_country_name'])\n",
    "        if event_id == 2117:\n",
    "            flood_event_info['properties']['cc'] = 'PRT, ESP, GIB, FRA, AND, ITA, MCO, UKR, ROU, POL, DEU, CZE, AUT, CHE, LIE, LUX, NLD, BEL, JEY, GGY'\n",
    "        elif event_id == 3145:\n",
    "            flood_event_info['properties']['cc'] = 'MLI, BFA'\n",
    "        elif event_id == 3494:\n",
    "            flood_event_info['properties']['cc'] = 'THA, CHN, LAO, KHM, VNM'\n",
    "        elif event_id == 4009:\n",
    "            flood_event_info['properties']['cc'] = 'GBR, IMN'\n",
    "        elif event_id == 4111:\n",
    "            flood_event_info['properties']['cc'] = 'GBR, IMN, IRL'\n",
    "        elif event_id == 4319:\n",
    "            flood_event_info['properties']['cc'] = 'GBR, IRL, IMN'\n",
    "        elif event_id == 4632:\n",
    "            flood_event_info['properties']['cc'] = 'THA, MMR, BGD, IND, CHN'\n",
    "        elif event_id == 4640:\n",
    "            flood_event_info['properties']['cc'] = 'IND, CHN, PAK, NPL'\n",
    "        elif event_id == 4645:\n",
    "            flood_event_info['properties']['cc'] = 'IND, CHN, AFG, PAK, NPL'\n",
    "        elif event_id == 4652:\n",
    "            flood_event_info['properties']['cc'] = 'THA, MMR, LAO, KHM, VNM'\n",
    "        elif event_id == 4653:\n",
    "            flood_event_info['properties']['cc'] = 'CHN, LAO, KHM, VNM'\n",
    "        elif event_id == 4654:\n",
    "            flood_event_info['properties']['cc'] = 'CHN, KAZ, RUS, MNG'\n",
    "        elif event_id == 4662:\n",
    "            flood_event_info['properties']['cc'] = 'BRA, VEN, GUY, COL'\n",
    "        elif event_id == 4665:\n",
    "            flood_event_info['properties']['cc'] = 'MMR, BGD, IND, CHN, BTN, NPL'\n",
    "        elif event_id == 4666:\n",
    "            flood_event_info['properties']['cc'] = 'MMR, BGD, IND, CHN'\n",
    "        elif event_id == 4667:\n",
    "            flood_event_info['properties']['cc'] = 'BEN, NGA, CMR, TCD, NER'\n",
    "        elif event_id == 4673:\n",
    "            flood_event_info['properties']['cc'] = 'BGD, IND, CHN, NPL'\n",
    "        elif event_id == 4676:\n",
    "            flood_event_info['properties']['cc'] = 'USA'\n",
    "        elif event_id == 4683:\n",
    "            flood_event_info['properties']['cc'] = 'BFA, TGO, GHA, CIV, BEN'\n",
    "        elif event_id == 4695:\n",
    "            flood_event_info['properties']['cc'] = 'USA, MEX'\n",
    "        elif event_id == 4703:\n",
    "            flood_event_info['properties']['cc'] = 'BRA, BOL, PRY, ARG'\n",
    "        elif event_id == 4704:\n",
    "            flood_event_info['properties']['cc'] = 'THA, LAO, KHM, VNM'\n",
    "        elif event_id == 4711:\n",
    "            flood_event_info['properties']['cc'] = 'USA, MEX'\n",
    "\n",
    "        # Check if 'cc' exists in the properties\n",
    "        if 'cc' in flood_event_info['properties']:\n",
    "            event_coun_code = flood_event_info['properties']['cc']\n",
    "            print(\"DFO {0} is in {1}\".format(event_id, event_coun_code))\n",
    "        else:\n",
    "            # 'cc' not found, so print 'gfd_country_name' and event_id\n",
    "            gfd_country_name = flood_event_info['properties'].get('gfd_country_name', 'Unknown Country Name')\n",
    "            print(\"Property 'cc' not found for event ID {}. Country: {}\".format(event_id, gfd_country_name))\n",
    "        country_codes_list = event_coun_code.split(', ')\n",
    "\n",
    "            \n",
    "        # add the layer of percipitation, dem & slope, impervious area percentage & CM\n",
    "        max_pre_map_13730 = max_cumu_prec13730(flood_event)\n",
    "\n",
    "        pre_scale = max_pre_map_13730['1-day'].projection().nominalScale()\n",
    "        \n",
    "\n",
    "\n",
    "        # add the layer of dem & slope\n",
    "        event_dem, event_slope = dem_slope(flood_event) \n",
    "        dem_slo_scale = event_dem.projection().nominalScale()\n",
    "\n",
    "        # add the layer of GISD & GCN\n",
    "        gisd, gcn = event_GISD_GCN(flood_event)\n",
    "        gisd_scale = gisd.projection().nominalScale()\n",
    "        gcn_scale = gcn.projection().nominalScale()\n",
    "\n",
    "        flood_extent, flood_duration, pop_img, pop_masked, pop_duration = get_flood_pop_pixel(flood_event)\n",
    "\n",
    "        # Filter the regions covered by the flood event\n",
    "        # gdf_coun = gdf[gdf['code'].isin(country_codes_list)]\n",
    "        gdf_coun = gdf.filter(ee.Filter.inList('code', ee.List(country_codes_list)))\n",
    "\n",
    "        covered_regions = gdf_coun.filterBounds(flood_extent.geometry())\n",
    "        numberOfRegions = covered_regions.size()\n",
    "\n",
    "        # Use getInfo() to retrieve the number and print it\n",
    "        print(\"found {} regions covered by the flood event\".format(numberOfRegions.getInfo()))\n",
    "\n",
    "        covered_regions_fea_coll = covered_regions\n",
    "        # Get area of flood in the scale of the flood map\n",
    "        flood_area_img = flood_extent.multiply(ee.Image.pixelArea())\n",
    "        map_scale = flood_extent.projection().nominalScale()\n",
    "        \n",
    "        pop_scale = pop_img.projection().nominalScale()\n",
    "\n",
    "        pop_masked_scale = pop_masked.projection().nominalScale()\n",
    "\n",
    "        pop_duration_scale = pop_duration.projection().nominalScale()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        def get_regions_dura(ft):\n",
    "            '''\n",
    "            This function calculates the population exposure and duration of each flood event\n",
    "            for each administrative region covered by the flood event\n",
    "            Input: ft - a feature from the feature collection of covered regions\n",
    "            '''\n",
    "\n",
    "            def format_number(number):\n",
    "                return ee.Number(number).format('%.2f')\n",
    "\n",
    "            # Initialize a dictionary with all required properties set to None\n",
    "            properties = {\n",
    "                \"eveId\": None, \"eveBegan\": None, \"geoCounCo\": None, \n",
    "                \"geoCode\": None, \"geoLevel\": None, \"incoMean\": None, \n",
    "                \"incoMedi\": None, \"incoGini\": None, \"incoThei\": None,\n",
    "                \"poor215\": None, \"poor365\": None, \"poor685\": None, \n",
    "                \"popAll\": None, \"popExposed\": None, \"durPopSum\": None, \n",
    "                \"durPopMean\": None, \"durCelMean\": None, \"durCelMax\": None,\n",
    "                \"percMax1\": None, \"percMax3\": None, \"percMax7\": None, \"percMax30\": None,\n",
    "                \"demMean\": None, \"slopeMean\": None,\n",
    "                \"infRatMea\": None, \"CMMean\": None,\n",
    "            }\n",
    "\n",
    "            pop_sum = pop_img.reduceRegion(\n",
    "            reducer = ee.Reducer.sum(),\n",
    "            geometry = ft.geometry(),\n",
    "            scale = pop_scale,\n",
    "            maxPixels = 1e9,\n",
    "            bestEffort = True)\n",
    "\n",
    "            area_sum= flood_area_img.reduceRegion(\n",
    "            reducer= ee.Reducer.sum(),\n",
    "            geometry= ft.geometry(),\n",
    "            scale= map_scale,\n",
    "            maxPixels= 1e9,\n",
    "            bestEffort = True)\n",
    "\n",
    "            pop_exposed= pop_masked.reduceRegion(\n",
    "            reducer= ee.Reducer.sum(),\n",
    "            geometry= ft.geometry(),\n",
    "            scale= pop_masked_scale,\n",
    "            maxPixels= 1e9,\n",
    "            bestEffort = True)\n",
    "\n",
    "            pop_duration_mask = pop_duration.reduceRegion(\n",
    "            reducer= ee.Reducer.sum(),\n",
    "            geometry= ft.geometry(),\n",
    "            scale= pop_duration_scale,\n",
    "            maxPixels= 1e9,\n",
    "            bestEffort = True)\n",
    "\n",
    "            duration_mean_mask = flood_duration.reduceRegion(\n",
    "            reducer= ee.Reducer.mean(),\n",
    "            geometry= ft.geometry(),\n",
    "            scale= map_scale,\n",
    "            maxPixels= 1e9,\n",
    "            bestEffort = True)\n",
    "\n",
    "            duration_max_mask = flood_duration.reduceRegion(\n",
    "            reducer= ee.Reducer.max(),\n",
    "            geometry= ft.geometry(),\n",
    "            scale= map_scale,\n",
    "            maxPixels= 1e9,\n",
    "            bestEffort = True)\n",
    "\n",
    "            mean_max_pre_map_1 = max_pre_map_13730['1-day'].reduceRegion(\n",
    "                reducer= ee.Reducer.mean(),\n",
    "                geometry= ft.geometry(),\n",
    "                scale=pre_scale,\n",
    "                maxPixels= 1e9,\n",
    "                bestEffort = True)\n",
    "            mean_max_pre_map_1 = format_number(mean_max_pre_map_1.get(\"precipitationCal_max\"))\n",
    "            if \"3-day\" in max_pre_map_13730.keys():\n",
    "                mean_max_pre_map_3 = max_pre_map_13730['3-day'].reduceRegion(\n",
    "                    reducer= ee.Reducer.mean(),\n",
    "                    geometry= ft.geometry(),\n",
    "                    scale=pre_scale,\n",
    "                    maxPixels= 1e9,\n",
    "                bestEffort = True)\n",
    "                mean_max_pre_map_3 = format_number(mean_max_pre_map_3.get(\"precipitationCal_max\"))\n",
    "            else:\n",
    "                mean_max_pre_map_3 = None\n",
    "                \n",
    "            if \"7-day\" in max_pre_map_13730.keys():\n",
    "                mean_max_pre_map_7 = max_pre_map_13730['7-day'].reduceRegion(\n",
    "                    reducer= ee.Reducer.mean(),\n",
    "                    geometry= ft.geometry(),\n",
    "                    scale=pre_scale,\n",
    "                    maxPixels= 1e9,\n",
    "                bestEffort = True)\n",
    "                mean_max_pre_map_7 = format_number(mean_max_pre_map_7.get(\"precipitationCal_max\"))\n",
    "            else:\n",
    "                mean_max_pre_map_7 = None\n",
    "            if \"30-day\" in max_pre_map_13730.keys():\n",
    "                mean_max_pre_map_30 = max_pre_map_13730['30-day'].reduceRegion(\n",
    "                    reducer= ee.Reducer.mean(),\n",
    "                    geometry= ft.geometry(),\n",
    "                    scale=pre_scale,\n",
    "                    maxPixels= 1e9,\n",
    "                bestEffort = True)\n",
    "                mean_max_pre_map_30 = format_number(mean_max_pre_map_30.get(\"precipitationCal_max\"))\n",
    "            else:\n",
    "                mean_max_pre_map_30 = None\n",
    "\n",
    "            dem_mean = event_dem.reduceRegion(\n",
    "                reducer= ee.Reducer.mean(),\n",
    "                geometry= ft.geometry(),\n",
    "                scale= dem_slo_scale,\n",
    "                maxPixels= 1e9,\n",
    "                bestEffort = True)\n",
    "            dem_mean = format_number(dem_mean.get(\"b1\"))\n",
    "\n",
    "            slope_mean = event_slope.reduceRegion(\n",
    "                reducer= ee.Reducer.mean(),\n",
    "                geometry= ft.geometry(),\n",
    "                scale= dem_slo_scale,\n",
    "                maxPixels= 1e9,\n",
    "                bestEffort = True)\n",
    "            slope_mean = format_number(slope_mean.get(\"slope\"))\n",
    "\n",
    "            gisd_mean = gisd.reduceRegion(\n",
    "                reducer= ee.Reducer.mean(),\n",
    "                geometry= ft.geometry(),\n",
    "                scale= gisd_scale,\n",
    "                maxPixels= 1e9,\n",
    "                bestEffort = True)\n",
    "            gisd_mean = format_number(gisd_mean.get(\"b1\"))\n",
    "\n",
    "            gcn_mean = gcn.reduceRegion(\n",
    "                reducer= ee.Reducer.mean(),\n",
    "                geometry= ft.geometry(),\n",
    "                scale= gcn_scale,\n",
    "                maxPixels= 1e9,\n",
    "                bestEffort = True)\n",
    "            gcn_mean = format_number(gcn_mean.get(\"b1\"))\n",
    "\n",
    "            pop_init_sum = format_number(pop_sum.get(\"population_count\"))\n",
    "            pop_exposed_sum = pop_exposed.get(\"population_count\")\n",
    "            pop_duration_mask_sum = pop_duration_mask.get(\"population_count\")\n",
    "\n",
    "            # Calculate the ratio of pop_duration_mask_sum to pop_exposed_sum\n",
    "            # Ensure that pop_exposed_sum is not zero to avoid division by zero error\n",
    "\n",
    "            duration_pop_mean = ee.Algorithms.If(\n",
    "                ee.Number(pop_exposed_sum).gt(0),\n",
    "                format_number(ee.Number(pop_duration_mask_sum).divide(pop_exposed_sum)),\n",
    "                ''\n",
    "            )\n",
    "            pop_exposed_sum = format_number(pop_exposed.get(\"population_count\"))\n",
    "\n",
    "            duration_pop_sum = ee.Algorithms.If(\n",
    "                pop_duration_mask_sum,\n",
    "                format_number(pop_duration_mask_sum),\n",
    "                ''  # Use -1 to represent None\n",
    "            )\n",
    "            duration_cell_mean = ee.Algorithms.If(\n",
    "                duration_mean_mask.get(\"duration\"),\n",
    "                format_number(ee.Number(duration_mean_mask.get(\"duration\"))),\n",
    "                ''  # Use -1 to represent None\n",
    "            )\n",
    "\n",
    "            duration_cell_max = ee.Algorithms.If(\n",
    "                duration_max_mask.get(\"duration\"),\n",
    "                format_number(ee.Number(duration_max_mask.get(\"duration\"))),\n",
    "                ''  # Use -1 to represent None\n",
    "            )\n",
    "            income_mean = ee.Algorithms.If(\n",
    "                ft.get(\"GSAP2_mean\"),\n",
    "                ee.Number.parse(ft.get(\"GSAP2_mean\")).format('%.2f'),\n",
    "                ''  # Use -1 to represent None\n",
    "                )\n",
    "            income_medi = ee.Algorithms.If(\n",
    "                ft.get(\"GSAP2_medi\"),\n",
    "                ee.Number.parse(ft.get(\"GSAP2_medi\")).format('%.2f'),\n",
    "                ''  # Use -1 to represent None\n",
    "                )\n",
    "            income_gini = ee.Algorithms.If(\n",
    "                ft.get(\"GSAP2_gini\"),\n",
    "                ee.Number.parse(ft.get(\"GSAP2_gini\")).format('%.2f'),\n",
    "                ''  # Use -1 to represent None\n",
    "                )\n",
    "            income_thei = ee.Algorithms.If(\n",
    "                ft.get(\"GSAP2_thei\"),\n",
    "                ee.Number.parse(ft.get(\"GSAP2_thei\")).format('%.2f'),\n",
    "                ''  # Use -1 to represent None\n",
    "                )\n",
    "\n",
    "            # Update the dictionary with actual values from calculations\n",
    "            properties.update({\n",
    "                \"eveId\": event_id,\n",
    "                \"eveBegan\": flood_event.get(\"began\"),\n",
    "                \"geoCounCo\": ft.get(\"code\"),\n",
    "                \"geoCode\": ft.get(\"geo_code2\"),\n",
    "                \"geoLevel\": ft.get(\"level\"),\n",
    "                \"incoMean\": income_mean,\n",
    "                \"incoMedi\": income_medi,\n",
    "                \"incoGini\": income_gini,\n",
    "                \"incoThei\": income_thei,\n",
    "                \"poor215\": ft.get(\"GSAP2_poor\"),\n",
    "                \"poor365\": ft.get(\"GSAP2_po_1\"),\n",
    "                \"poor685\": ft.get(\"GSAP2_po_2\"),\n",
    "                \"popAll\": pop_init_sum,\n",
    "                \"popExposed\": pop_exposed_sum,\n",
    "                \"durPopSum\": duration_pop_sum,\n",
    "                \"durPopMean\": duration_pop_mean,\n",
    "                \"durCelMean\": duration_cell_mean,\n",
    "                \"durCelMax\": duration_cell_max,\n",
    "                \"percMax1\": mean_max_pre_map_1,\n",
    "                \"percMax3\": mean_max_pre_map_3,\n",
    "                \"percMax7\": mean_max_pre_map_7,\n",
    "                \"percMax30\": mean_max_pre_map_30,\n",
    "                \"demMean\": dem_mean,\n",
    "                \"slopeMean\": slope_mean,\n",
    "                \"infRatMea\": gisd_mean,\n",
    "                \"CMMean\": gcn_mean,\n",
    "            })\n",
    "            # \"percMax1\": None, \"percMax3\": None, \"percMax7\": None, \"percMax30\": None,\n",
    "            # \"demMean\": None, \"slopeMean\": None,\n",
    "            # \"infRatMea\": None, \"CMMean\": None,\n",
    "            # return ee.Feature(ft.geometry(), properties)\n",
    "            return ee.Feature(None, properties)\n",
    "        # format_number(ee.Number(duration_mean_mask.get(\"duration\")))\n",
    "        \n",
    "            \n",
    "        try:\n",
    "            # regions_stats_ge = ee.FeatureCollection(covered_regions_fea_coll).map(get_regions_dura_ge)\n",
    "            regions_stats = ee.FeatureCollection(covered_regions_fea_coll).map(get_regions_dura)\n",
    "            # regions_stats = ee.FeatureCollection(regions_stats).set({\"id\":event_id})\n",
    "            print(\"calculated results for DFO {0}...\".format(int(event_id)))\n",
    "            # print(regions_stats.first().getInfo())\n",
    "            # Append regions_stats to the list\n",
    "            all_regions_stats.append(regions_stats)\n",
    "            # all_regions_stats_ge.append(regions_stats_ge)\n",
    "        except Exception as e:\n",
    "            s = str(e)\n",
    "            with open(log_file,\"w\", newline='') as out_file:\n",
    "                wr = csv.writer(out_file)\n",
    "                wr.writerow([\"Calculation Error\", event_id, s])\n",
    "            print(\"Calculation Error {0} - Cataloguing and moving onto next event\".format(event_id))\n",
    "            print(s)\n",
    "            print(\"-------------------------------------------------\")\n",
    "\n",
    "        # Export results\n",
    "        try:\n",
    "            print(\"Exporting FeatureCollection to CSV..._{0}\".format(str(int(event_id))))\n",
    "            task = ee.batch.Export.table.toDrive(\n",
    "                collection = regions_stats,\n",
    "                description = 'csv for duration_state_regions_{0}'.format(str(int(event_id))),\n",
    "                folder='GFD_region_duration_factors_csv',\n",
    "                fileNamePrefix = 'duration_state_regions_{0}'.format(str(int(event_id))),\n",
    "                fileFormat = 'CSV')\n",
    "            task.start()\n",
    "        except Exception as e:\n",
    "            s = str(e)\n",
    "            with open(log_file,\"ab\") as out_file:\n",
    "                wr = csv.writer(out_file)\n",
    "                wr.writerow([\"Export Error\", event_id, s])\n",
    "            print(\"Export Error DFO {0} - Cataloguing and moving onto next event\".format(event_id))\n",
    "            print(\"-------------------------------------------------\")\n",
    "\n",
    "        # try:\n",
    "        #     # collection = regions_stats_ge,\n",
    "        #     print(\"Exporting FeatureCollection to SHP..._{0}\".format(str(int(event_id))))\n",
    "        #     def addGeometryType(feature):\n",
    "        #         geomType = feature.geometry().type()\n",
    "        #         return feature.set('geomType', geomType)\n",
    "        #     regions_stats_ge = regions_stats_ge.map(addGeometryType)\n",
    "        #     regions_stats_ge = regions_stats_ge.filter(ee.Filter.eq('geomType', 'Polygon'))\n",
    "        #     task = ee.batch.Export.table.toDrive(\n",
    "        #         collection = regions_stats_ge,\n",
    "        #         description = 'shp for duration_state_regions_{0}'.format(str(int(event_id))),\n",
    "        #         folder='GFD_region_duration_shp',\n",
    "        #         fileNamePrefix = 'duration_state_regions_{0}'.format(str(int(event_id))),\n",
    "        #         fileFormat = 'SHP')\n",
    "        #     task.start()\n",
    "        # except Exception as e:\n",
    "        #     s = str(e)\n",
    "        #     with open(log_file,\"ab\") as out_file:\n",
    "        #         wr = csv.writer(out_file)\n",
    "        #         wr.writerow([\"Export Error\", event_id, s])\n",
    "        #     print(\"Export Error DFO {0} - Cataloguing and moving onto next event\".format(event_id))\n",
    "        #     print(\"-------------------------------------------------\")\n",
    "\n",
    "# After the loop, merge all FeatureCollections into one\n",
    "# all_regions_stats_fc = ee.FeatureCollection(all_regions_stats).flatten()\n",
    "# print(all_regions_stats_fc.first().getInfo())\n",
    "# all_regions_stats_ge_fc = ee.FeatureCollection(all_regions_stats_ge).flatten()\n",
    "# # Export the merged FeatureCollection to a CSV\n",
    "# try:\n",
    "#     print(\"Exporting merged FeatureCollection to CSV...\")\n",
    "#     task = ee.batch.Export.table.toDrive(\n",
    "#         collection = all_regions_stats_fc,\n",
    "#         description = 'all_duration_state_regions_csv',\n",
    "#         folder = 'GFD_region_duration_all',\n",
    "#         fileNamePrefix = 'all_duration_state_regions',\n",
    "#         fileFormat = 'CSV')\n",
    "#     task.start()\n",
    "# except Exception as e:\n",
    "#     s = str(e)\n",
    "#     with open(log_file,\"ab\") as out_file:\n",
    "#         wr = csv.writer(out_file)\n",
    "#         wr.writerow([\"Export Error to save all information to one .csv\"])\n",
    "#     print(\"-------------------------------------------------\")\n",
    "\n",
    "# try:\n",
    "#     print(\"Exporting merged FeatureCollection to SHP...\")\n",
    "#     task = ee.batch.Export.table.toDrive(\n",
    "#         collection = all_regions_stats_ge_fc,\n",
    "#         description = 'all_duration_state_regions_shp',\n",
    "#         folder = 'GFD_region_duration_shp',\n",
    "#         fileNamePrefix = 'all_duration_state_regions',\n",
    "#         fileFormat = 'SHP')\n",
    "#     task.start()\n",
    "# except Exception as e:\n",
    "#     s = str(e)\n",
    "#     with open(log_file,\"ab\") as out_file:\n",
    "#         wr = csv.writer(out_file)\n",
    "#         print(e)\n",
    "#         wr.writerow([\"Export Error to save all information to one .shp\", e])\n",
    "#     print(\"-------------------------------------------------\")\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. to one .csv\n",
    "2. visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chongyang Du\n",
    "# Jan 2, 2024\n",
    "\n",
    "# use this template to run the flood stats functions (area, population, etc.)\n",
    "# on an image collection and export results as a .tif\n",
    "\n",
    "import ee\n",
    "import geemap\n",
    "ee.Initialize()\n",
    "\n",
    "# from flood_stats import pop_utils\n",
    "import time, csv\n",
    "\n",
    "def get_flood_pop_pixel(flood_img):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        floodImage : the standard Earth Engine Image object outputted by the map_DFO_event function\n",
    "        roiGEO : the region of interest as an Earth Engine Geometry object\n",
    "\n",
    "    Returns:\n",
    "    -an image of people in the mapped flood from WorldPop data\n",
    "\n",
    "    \"\"\"\n",
    "    import ee\n",
    "    import geemap\n",
    "    ee.Initialize()\n",
    "    # ee.Authenticate()\n",
    "    roi_geo = flood_img.geometry()\n",
    "\n",
    "    # Import the LandScan image collection & permannt water mask\n",
    "    perm_water = ee.Image(\"JRC/GSW1_0/GlobalSurfaceWater\").select(\"transition\").eq(1).unmask()\n",
    "    # print('Band names:', flood_img.bandNames().getInfo())\n",
    "    def maskImages(img):\n",
    "        non_flood = img.select(\"flooded\")\n",
    "        water_mask = non_flood.multiply(perm_water.neq(1))\n",
    "        return img.select(\"flooded\").mask(water_mask)\n",
    "\n",
    "    def durationImages(img):\n",
    "            non_flood = img.select(\"flooded\")\n",
    "            water_mask = non_flood.multiply(perm_water.neq(1))\n",
    "            return img.select(\"duration\").mask(water_mask)\n",
    "\n",
    "    # Extract the final flood extent image data as its own variable for analysis\n",
    "    # flood_extent = maskImages(ee.Image(flood_img.select(\"flooded\")))\n",
    "    # flood_duration = durationImages(ee.Image(flood_img.select(\"flood_duration\")))\n",
    "    flood_extent = maskImages(ee.Image(flood_img))\n",
    "    flood_duration = durationImages(ee.Image(flood_img))\n",
    "\n",
    "\n",
    "    # # get pop from projects/global-flood-db/landscan\n",
    "    # # Get event year, match with the population year and clip to study are\n",
    "    # pop_all = ee.ImageCollection(\"projects/global-flood-db/landscan\")\n",
    "    # event_year = ee.Date(flood_img.get('began')).get('year')\n",
    "    # pop_img = ee.Image(pop_all.filterMetadata('year', 'equals', event_year)\\\n",
    "    #                 .first()).clip(roi_geo)\n",
    "    # pop_img = pop_img.updateMask(pop_img.gte(0)) # mask out bad data with negative values\n",
    "\n",
    "    # get pop from JRC/GHSL/P2016/POP_GPW_GLOBE_V1\n",
    "    pop_all = ee.ImageCollection(\"JRC/GHSL/P2016/POP_GPW_GLOBE_V1\")\n",
    "    # Get event year to match with the population year\n",
    "    # pop_img = ee.Image(pop_all.filterMetadata('system:index', 'equals', '2000')\\\n",
    "    #                 .first()).clip(roi_geo)\n",
    "    pop_img = ee.Image(pop_all.filterMetadata('system:index', 'equals', '2015')\\\n",
    "                    .first()).clip(roi_geo)\n",
    "\n",
    "\n",
    "    # Mask the world population dataset using the flood extent layer\n",
    "    pop_masked = pop_img.updateMask(flood_extent)\n",
    "\n",
    "    pop_duration = pop_masked.multiply(flood_duration)\n",
    "    return flood_extent, flood_duration, pop_img, pop_masked, pop_duration\n",
    "\n",
    "\n",
    "\n",
    "# Image Collection of flood maps, each needs layer called \"flooded\" that\n",
    "# is 1 = flooded, 0 = not flooded\n",
    "gfd = ee.ImageCollection('projects/global-flood-db/gfd_v3')\n",
    "# gfd = ee.ImageCollection('projects/global-flood-db/gfd_v3').filterMetadata('id','greater_than',4335)\n",
    "\n",
    "# Create Error Log file\n",
    "log_file = \"error_logs/event_stats/pop_error_log_{0}.csv\".format(time.strftime(\"%d_%m_%Y\"))\n",
    "with open(log_file,\"w\", newline='') as out_file:\n",
    "    wr = csv.writer(out_file)\n",
    "    wr.writerow([\"error_type\", \"dfo_id\", \"error_message\"])\n",
    "\n",
    "# Create list of events from input fusion table\n",
    "event_ids = ee.List(gfd.aggregate_array('id')).sort()\n",
    "id_list = event_ids.getInfo()\n",
    "id_list = [int(i) for i in id_list]\n",
    "\n",
    "# for event_id in id_list:\n",
    "# event_id = id_list[0]\n",
    "event_id = 4444\n",
    "# Get event date range, they can be passed as Strings\n",
    "flood_event = ee.Image(gfd.filterMetadata('id', 'equals', event_id).first())\n",
    "\n",
    "# try:\n",
    "# Calculate flood stats\n",
    "# flood_stats = pop_utils.getFloodPopbyCountry_GHSLTimeSeries(flood_event)\n",
    "flood_extent, flood_duration, pop_img, pop_masked, pop_duration = get_flood_pop_pixel(flood_event)\n",
    "# index = flood_stats.get(\"id\").getInfo()\n",
    "print(\"calculated results, exporting results for DFO {0}...\".format(event_id))\n",
    "\n",
    "# 定义感兴趣的区域\n",
    "region = pop_img.geometry()\n",
    "\n",
    "# 设置下载参数\n",
    "output_dir = '/download/'\n",
    "scale = pop_img.projection().nominalScale()  # 设置所需的空间分辨率\n",
    "file_format = 'GeoTIFF'  # 设置所需的文件格式\n",
    "\n",
    "# 下载图像集合\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/flooded_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(flood_extent, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/flood_duration_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(flood_duration, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/pop_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(pop_img, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/pop_flooded_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(pop_masked, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "filename = \"Data/GFD/duration_pop_extent/pop_duration_{0}.tif\".format(event_id)\n",
    "geemap.download_ee_image(pop_duration, scale=scale, region=region, filename=filename, crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite_flooding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
